{"ast":null,"code":"import \"core-js/modules/es.typed-array.to-reversed.js\";\nimport \"core-js/modules/es.typed-array.to-sorted.js\";\nimport \"core-js/modules/es.typed-array.with.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Cast, util } from '@tensorflow/tfjs-core';\nimport { createSimpleBinaryKernelImpl } from '../utils/binary_impl';\nimport { zeros } from '../utils/zeros_impl';\nimport { complex } from './Complex';\nimport { identity } from './Identity';\nimport { real } from './Real';\nexport function cast(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    dtype\n  } = attrs;\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({\n        inputs: {\n          x\n        },\n        backend\n      });\n    }\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        dtype: 'float32'\n      }\n    });\n    const result = complex({\n      inputs: {\n        real: floatX,\n        imag: zerosTensorInfo\n      },\n      backend\n    });\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n    return result;\n  }\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({\n      inputs: {\n        input: x\n      },\n      backend\n    });\n    const result = cast({\n      inputs: {\n        x: realPart\n      },\n      backend,\n      attrs: {\n        dtype\n      }\n    });\n    backend.disposeIntermediateTensorInfo(realPart);\n    return result;\n  }\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({\n      inputs: {\n        x\n      },\n      backend\n    });\n    return {\n      dataId: result.dataId,\n      shape: result.shape,\n      dtype\n    };\n  }\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values;\n    const zero = util.toTypedArray([0], x.dtype);\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\nexport const castConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast\n};","map":{"version":3,"names":["Cast","util","createSimpleBinaryKernelImpl","zeros","complex","identity","real","cast","args","inputs","backend","attrs","x","dtype","zerosTensorInfo","shape","floatX","result","imag","disposeIntermediateTensorInfo","realPart","input","hasEncodingLoss","dataId","values","data","get","resultValues","Int32Array","from","makeTensorInfo","xVals","zero","toTypedArray","resultData","resultShape","a","b","Error","castConfig","kernelName","backendName","kernelFunc"],"sources":["../../../../../../tfjs-backend-cpu/src/kernels/Cast.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n"],"mappings":";;;AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,IAAI,EAA2EC,IAAI,QAAO,uBAAuB;AAGzH,SAAQC,4BAA4B,QAAO,sBAAsB;AACjE,SAAQC,KAAK,QAAO,qBAAqB;AAEzC,SAAQC,OAAO,QAAO,WAAW;AACjC,SAAQC,QAAQ,QAAO,YAAY;AACnC,SAAQC,IAAI,QAAO,QAAQ;AAE3B,OAAM,SAAUC,IAAIA,CAChBC,IAAqE;EAEvE,MAAM;IAACC,MAAM;IAAEC,OAAO;IAAEC;EAAK,CAAC,GAAGH,IAAI;EACrC,MAAM;IAACI;EAAC,CAAC,GAAGH,MAAM;EAClB,MAAM;IAACI;EAAK,CAAC,GAAGF,KAAK;EAErB;EACA,IAAIE,KAAK,KAAK,WAAW,EAAE;IACzB,IAAID,CAAC,CAACC,KAAK,KAAK,WAAW,EAAE;MAC3B,OAAOR,QAAQ,CAAC;QAACI,MAAM,EAAE;UAACG;QAAC,CAAC;QAAEF;MAAO,CAAC,CAAC;;IAGzC,MAAMI,eAAe,GAAGX,KAAK,CAACO,OAAO,EAAEE,CAAC,CAACG,KAAK,EAAEH,CAAC,CAACC,KAAK,CAAC;IACxD,MAAMG,MAAM,GAAGT,IAAI,CAAC;MAACE,MAAM,EAAE;QAACG;MAAC,CAAC;MAAEF,OAAO;MAAEC,KAAK,EAAE;QAACE,KAAK,EAAE;MAAS;IAAC,CAAC,CAAC;IAEtE,MAAMI,MAAM,GACRb,OAAO,CAAC;MAACK,MAAM,EAAE;QAACH,IAAI,EAAEU,MAAM;QAAEE,IAAI,EAAEJ;MAAe,CAAC;MAAEJ;IAAO,CAAC,CAAC;IAErEA,OAAO,CAACS,6BAA6B,CAACL,eAAe,CAAC;IACtDJ,OAAO,CAACS,6BAA6B,CAACH,MAAM,CAAC;IAE7C,OAAOC,MAAM;;EAGf;EACA,IAAIL,CAAC,CAACC,KAAK,KAAK,WAAW,EAAE;IAC3B,MAAMO,QAAQ,GAAGd,IAAI,CAAC;MAACG,MAAM,EAAE;QAACY,KAAK,EAAET;MAAC,CAAC;MAAEF;IAAO,CAAC,CAAC;IACpD,MAAMO,MAAM,GAAGV,IAAI,CAAC;MAACE,MAAM,EAAE;QAACG,CAAC,EAAEQ;MAAQ,CAAC;MAAEV,OAAO;MAAEC,KAAK,EAAE;QAACE;MAAK;IAAC,CAAC,CAAC;IAErEH,OAAO,CAACS,6BAA6B,CAACC,QAAQ,CAAC;IAE/C,OAAOH,MAAM;;EAGf,IAAI,CAAChB,IAAI,CAACqB,eAAe,CAACV,CAAC,CAACC,KAAK,EAAEA,KAAK,CAAC,EAAE;IACzC;IACA;IACA,MAAMI,MAAM,GAAGZ,QAAQ,CAAC;MAACI,MAAM,EAAE;QAACG;MAAC,CAAC;MAAEF;IAAO,CAAC,CAAC;IAC/C,OAAO;MAACa,MAAM,EAAEN,MAAM,CAACM,MAAM;MAAER,KAAK,EAAEE,MAAM,CAACF,KAAK;MAAEF;IAAK,CAAC;;EAG5D,IAAIA,KAAK,KAAK,OAAO,EAAE;IACrB,MAAMW,MAAM,GAAGd,OAAO,CAACe,IAAI,CAACC,GAAG,CAACd,CAAC,CAACW,MAAM,CAAC,CAACC,MAAoB;IAC9D,MAAMG,YAAY,GAAGC,UAAU,CAACC,IAAI,CAACL,MAAM,CAAC;IAC5C,OAAOd,OAAO,CAACoB,cAAc,CAAClB,CAAC,CAACG,KAAK,EAAE,OAAO,EAAEY,YAAY,CAAC;;EAG/D,IAAId,KAAK,KAAK,MAAM,EAAE;IACpB;IACA;IACA;IACA,MAAMkB,KAAK,GAAGrB,OAAO,CAACe,IAAI,CAACC,GAAG,CAACd,CAAC,CAACW,MAAM,CAAC,CAACC,MAAoB;IAC7D,MAAMQ,IAAI,GAAG/B,IAAI,CAACgC,YAAY,CAAC,CAAC,CAAC,CAAC,EAAErB,CAAC,CAACC,KAAK,CAAC;IAE5C,MAAM,CAACqB,UAAU,EAAEC,WAAW,CAAC,GAAGjC,4BAA4B,CAC1D,CAACkC,CAAC,EAAEC,CAAC,KAAMD,CAAC,KAAKC,CAAC,GAAI,CAAC,GAAG,CAAC,CAAC,CAACzB,CAAC,CAACG,KAAK,EAAE,EAAE,EAAEgB,KAAK,EAAEC,IAAI,EAAE,MAAM,CAAC;IAElE,OAAOtB,OAAO,CAACoB,cAAc,CAACK,WAAW,EAAE,MAAM,EAAED,UAAU,CAAC;;EAGhE,MAAM,IAAII,KAAK,CAAC,iCAAiC1B,CAAC,CAACC,KAAK,OAAOA,KAAK,EAAE,CAAC;AACzE;AAEA,OAAO,MAAM0B,UAAU,GAAiB;EACtCC,UAAU,EAAExC,IAAI;EAChByC,WAAW,EAAE,KAAK;EAClBC,UAAU,EAAEnC;CACb"},"metadata":{},"sourceType":"module","externalDependencies":[]}