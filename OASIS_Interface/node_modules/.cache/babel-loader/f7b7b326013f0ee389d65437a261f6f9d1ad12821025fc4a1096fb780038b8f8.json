{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { Im2ColPackedProgram } from '../im2col_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\nimport { batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD } from './BatchMatMul_impl';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape';\nimport { transpose } from './Transpose';\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}) {\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  const xShape = x.shape;\n  const xTexData = backend.texData.get(x.dataId);\n  const sharedMatMulDim = convInfo.inChannels;\n  const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  const outerShapeFilter = convInfo.outChannels;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = false;\n  const transposeB = false;\n  let out;\n  const intermediates = [];\n  if (preluActivationWeights != null && !isChannelsLast && preluActivationWeights.shape.length === 3) {\n    // If PReLU's activation weights is NCHW format, then convert it to NHWC for\n    // the following computation.\n    const preluActivationWeightsInNhwcFormat = transpose({\n      inputs: {\n        x: preluActivationWeights\n      },\n      backend,\n      attrs: {\n        perm: [1, 2, 0]\n      }\n    });\n    intermediates.push(preluActivationWeightsInNhwcFormat);\n    preluActivationWeights = preluActivationWeightsInNhwcFormat;\n  }\n  // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n  const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n  // The algorithm in the if condition assumes (1) the output will be packed,\n  // (2) x is packed, (3) x isChannelsLast, (4)  x's packed texture is already\n  // on GPU, (5) col is odd, (6) the width, height and inChannels are the same\n  // for xTexData.shape and xShape.\n  const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked && isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 && util.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));\n  if (canOptimize) {\n    // We avoid expensive packed 2x2 reshape by padding col count to next,\n    // even number. When col is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for next even col. We make the odd-cols tensor to look like\n    // even-cols tensor before the operation and, after the batchMatMul,\n    // fix the even-cols result to have odd number of cols.\n    const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);\n    const xReshaped = {\n      dataId: x.dataId,\n      shape: [1, targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    };\n    // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing col count, after batchMatMul->...->compileProgram leads to\n    // invalid col count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even col count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n    const originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);\n    const filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n    intermediates.push(filterReshaped);\n    const pointwiseConv = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      backend,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n    const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(pointwiseConvTexData.isPacked, () => 'batchMatMul result is expected to be packed');\n    // Restore the input shape to original.\n    xTexData.shape = originalXTexDataShape;\n    // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n    pointwiseConvTexData.shape = convInfo.outShape;\n    out = identity({\n      inputs: {\n        x: pointwiseConv\n      },\n      backend\n    });\n    out.shape = convInfo.outShape;\n    intermediates.push(pointwiseConv);\n  } else {\n    const xInNhwcFormat = isChannelsLast ? x : transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: [0, 2, 3, 1]\n      }\n    });\n    const xInNhwcFormatShape = xInNhwcFormat.shape;\n    const targetShape = xInNhwcFormatShape[0] * xInNhwcFormatShape[1] * xInNhwcFormatShape[2];\n    const xReshaped = reshape({\n      inputs: {\n        x: xInNhwcFormat\n      },\n      backend,\n      attrs: {\n        shape: [1, targetShape, convInfo.inChannels]\n      }\n    });\n    const filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n    const result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA,\n      transposeB,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n    const outInNHWCFormatShape = [convInfo.batchSize, convInfo.outHeight, convInfo.outWidth, convInfo.outChannels];\n    const outInNHWCFormat = reshape({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        shape: outInNHWCFormatShape\n      }\n    });\n    // If the data format is NCHW, then convert the output to be NCHW format.\n    out = isChannelsLast ? outInNHWCFormat : transpose({\n      inputs: {\n        x: outInNHWCFormat\n      },\n      backend,\n      attrs: {\n        perm: [0, 3, 1, 2]\n      }\n    });\n    if (!isChannelsLast) {\n      intermediates.push(xInNhwcFormat);\n      intermediates.push(outInNHWCFormat);\n    }\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  }\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n  return out;\n}\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    outWidth,\n    outHeight,\n    dataFormat\n  } = convInfo;\n  const isChannelsLast = dataFormat === 'channelsLast';\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = [sharedDim, numCols];\n  const transposeA = true;\n  const transposeB = false;\n  const intermediates = [];\n  if (preluActivationWeights != null && !isChannelsLast && preluActivationWeights.shape.length === 3) {\n    // If PReLU's activation weights is NCHW format, then convert it to NHWC for\n    // the following computation.\n    const preluActivationWeightsInNhwcFormat = transpose({\n      inputs: {\n        x: preluActivationWeights\n      },\n      backend,\n      attrs: {\n        perm: [1, 2, 0]\n      }\n    });\n    intermediates.push(preluActivationWeightsInNhwcFormat);\n    preluActivationWeights = preluActivationWeightsInNhwcFormat;\n  }\n  const xSqueezed = reshape({\n    inputs: {\n      x\n    },\n    backend,\n    attrs: {\n      shape: x.shape.slice(1)\n    }\n  });\n  const w2Row = reshape({\n    inputs: {\n      x: filter\n    },\n    backend,\n    attrs: {\n      shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]\n    }\n  });\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);\n  const customValues = [xSqueezed.shape, [convInfo.padInfo.top, convInfo.padInfo.left], [convInfo.strideHeight, convInfo.strideWidth], [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inChannels], [convInfo.filterWidth * convInfo.inChannels], [convInfo.outWidth]];\n  const im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32', customValues);\n  const im2ColReshaped = reshape({\n    inputs: {\n      x: im2Col\n    },\n    backend,\n    attrs: {\n      shape: [1, x2ColShape[0], x2ColShape[1]]\n    }\n  });\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n  const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  const inputs = [im2ColReshaped, w2Row];\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n  const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n  const outInNHWCFormatShape = [1, outHeight, outWidth, convInfo.outChannels];\n  const outInNHWCFormat = reshape({\n    inputs: {\n      x: product\n    },\n    backend,\n    attrs: {\n      shape: outInNHWCFormatShape\n    }\n  });\n  // If the data format is NCHW, then convert the output to be NCHW format.\n  const out = isChannelsLast ? outInNHWCFormat : transpose({\n    inputs: {\n      x: outInNHWCFormat\n    },\n    backend,\n    attrs: {\n      perm: [0, 3, 1, 2]\n    }\n  });\n  if (!isChannelsLast) {\n    intermediates.push(outInNHWCFormat);\n  }\n  intermediates.push(product);\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n  return out;\n}","map":{"version":3,"names":["util","Im2ColPackedProgram","mapActivationToShaderProgram","MatMulPackedProgram","webgl_util","batchMatMulImpl","MATMUL_SHARED_DIM_THRESHOLD","identity","reshape","transpose","conv2dByMatMul","x","filter","convInfo","backend","bias","preluActivationWeights","leakyreluAlpha","activation","xShape","shape","xTexData","texData","get","dataId","sharedMatMulDim","inChannels","outerShapeX","outerShapeFilter","outChannels","isChannelsLast","dataFormat","transposeA","transposeB","out","intermediates","length","preluActivationWeightsInNhwcFormat","inputs","attrs","perm","push","batchMatMulWillBeUnpacked","canOptimize","isPacked","texture","arraysEqual","slice","targetShape","xReshaped","dtype","originalXTexDataShape","assert","isReshapeFree","filterReshaped","pointwiseConv","a","b","pointwiseConvTexData","outShape","xInNhwcFormat","xInNhwcFormatShape","result","outInNHWCFormatShape","batchSize","outHeight","outWidth","outInNHWCFormat","i","disposeIntermediateTensorInfo","conv2dWithIm2Row","filterWidth","filterHeight","sharedDim","numCols","x2ColShape","xSqueezed","w2Row","sizeFromShape","im2ColProgram","customValues","padInfo","top","left","strideHeight","strideWidth","dilationHeight","dilationWidth","im2Col","runWebGLProgram","im2ColReshaped","hasBias","hasPreluActivationWeights","hasLeakyreluAlpha","fusedActivation","matmulProgram","$leakyreluAlpha","makeTensorInfo","createScalarValue","product"],"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Conv2D_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\n// import {assertAndGetBroadcastShape} from\n// '../../../tfjs-core/src/ops/broadcast_util';\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {Im2ColPackedProgram} from '../im2col_packed_gpu';\nimport {mapActivationToShaderProgram} from '../kernel_utils/kernel_funcs_utils';\nimport {MatMulPackedProgram} from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\n\nimport {batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD} from './BatchMatMul_impl';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: MathBackendWebGL,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  const xShape = x.shape;\n  const xTexData = backend.texData.get(x.dataId);\n  const sharedMatMulDim = convInfo.inChannels;\n  const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  const outerShapeFilter = convInfo.outChannels;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = false;\n  const transposeB = false;\n\n  let out: TensorInfo;\n  const intermediates: TensorInfo[] = [];\n\n  if (preluActivationWeights != null && !isChannelsLast &&\n      preluActivationWeights.shape.length === 3) {\n    // If PReLU's activation weights is NCHW format, then convert it to NHWC for\n    // the following computation.\n    const preluActivationWeightsInNhwcFormat = transpose({\n      inputs: {x: preluActivationWeights},\n      backend,\n      attrs: {perm: [1, 2, 0]}\n    });\n    intermediates.push(preluActivationWeightsInNhwcFormat);\n    preluActivationWeights = preluActivationWeightsInNhwcFormat;\n  }\n\n  // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n  const batchMatMulWillBeUnpacked =\n      (outerShapeX === 1 || outerShapeFilter === 1) &&\n      sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n\n  // The algorithm in the if condition assumes (1) the output will be packed,\n  // (2) x is packed, (3) x isChannelsLast, (4)  x's packed texture is already\n  // on GPU, (5) col is odd, (6) the width, height and inChannels are the same\n  // for xTexData.shape and xShape.\n  const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked &&\n      isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 &&\n      util.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));\n\n  if (canOptimize) {\n    // We avoid expensive packed 2x2 reshape by padding col count to next,\n    // even number. When col is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for next even col. We make the odd-cols tensor to look like\n    // even-cols tensor before the operation and, after the batchMatMul,\n    // fix the even-cols result to have odd number of cols.\n    const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);\n    const xReshaped: TensorInfo = {\n      dataId: x.dataId,\n      shape: [1, targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    };\n    // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing col count, after batchMatMul->...->compileProgram leads to\n    // invalid col count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even col count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n    const originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(\n        webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape),\n        () => `packed reshape ${xTexData.shape} to ${\n            xReshaped.shape} isn't free`);\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    intermediates.push(filterReshaped);\n    const pointwiseConv = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      backend,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(\n        pointwiseConvTexData.isPacked,\n        () => 'batchMatMul result is expected to be packed');\n    // Restore the input shape to original.\n    xTexData.shape = originalXTexDataShape;\n    // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n    pointwiseConvTexData.shape = convInfo.outShape;\n\n    out = identity({inputs: {x: pointwiseConv}, backend});\n    out.shape = convInfo.outShape;\n\n    intermediates.push(pointwiseConv);\n  } else {\n    const xInNhwcFormat = isChannelsLast ?\n        x :\n        transpose({inputs: {x}, backend, attrs: {perm: [0, 2, 3, 1]}});\n    const xInNhwcFormatShape = xInNhwcFormat.shape;\n    const targetShape =\n        xInNhwcFormatShape[0] * xInNhwcFormatShape[1] * xInNhwcFormatShape[2];\n    const xReshaped = reshape({\n      inputs: {x: xInNhwcFormat},\n      backend,\n      attrs: {shape: [1, targetShape, convInfo.inChannels]}\n    });\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    const result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA,\n      transposeB,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    const outInNHWCFormatShape = [\n      convInfo.batchSize, convInfo.outHeight, convInfo.outWidth,\n      convInfo.outChannels\n    ];\n    const outInNHWCFormat = reshape(\n        {inputs: {x: result}, backend, attrs: {shape: outInNHWCFormatShape}});\n\n    // If the data format is NCHW, then convert the output to be NCHW format.\n    out = isChannelsLast ? outInNHWCFormat : transpose({\n      inputs: {x: outInNHWCFormat},\n      backend,\n      attrs: {perm: [0, 3, 1, 2]}\n    });\n    if (!isChannelsLast) {\n      intermediates.push(xInNhwcFormat);\n      intermediates.push(outInNHWCFormat);\n    }\n\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    outWidth,\n    outHeight,\n    dataFormat\n  } = convInfo;\n\n  const isChannelsLast = dataFormat === 'channelsLast';\n\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = [sharedDim, numCols];\n  const transposeA = true;\n  const transposeB = false;\n\n  const intermediates: TensorInfo[] = [];\n\n  if (preluActivationWeights != null && !isChannelsLast &&\n      preluActivationWeights.shape.length === 3) {\n    // If PReLU's activation weights is NCHW format, then convert it to NHWC for\n    // the following computation.\n    const preluActivationWeightsInNhwcFormat = transpose({\n      inputs: {x: preluActivationWeights},\n      backend,\n      attrs: {perm: [1, 2, 0]}\n    });\n    intermediates.push(preluActivationWeightsInNhwcFormat);\n    preluActivationWeights = preluActivationWeightsInNhwcFormat;\n  }\n\n  const xSqueezed =\n      reshape({inputs: {x}, backend, attrs: {shape: x.shape.slice(1)}});\n  const w2Row = reshape({\n    inputs: {x: filter},\n    backend,\n    attrs: {shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]}\n  });\n\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n\n  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);\n  const customValues = [\n    xSqueezed.shape, [convInfo.padInfo.top, convInfo.padInfo.left],\n    [convInfo.strideHeight, convInfo.strideWidth],\n    [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inChannels],\n    [convInfo.filterWidth * convInfo.inChannels], [convInfo.outWidth]\n  ];\n  const im2Col = backend.runWebGLProgram(\n      im2ColProgram, [xSqueezed], 'float32', customValues);\n  const im2ColReshaped = reshape({\n    inputs: {x: im2Col},\n    backend,\n    attrs: {shape: [1, x2ColShape[0], x2ColShape[1]]}\n  });\n\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const fusedActivation =\n      activation ? mapActivationToShaderProgram(activation, true) : null;\n  const matmulProgram = new MatMulPackedProgram(\n      im2ColReshaped.shape as [number, number, number],\n      w2Row.shape as [number, number, number],\n      [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias,\n      fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  const inputs: TensorInfo[] = [im2ColReshaped, w2Row];\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo(\n        [], 'float32',\n        util.createScalarValue(leakyreluAlpha as {} as 'float32', 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n  const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n\n  const outInNHWCFormatShape = [1, outHeight, outWidth, convInfo.outChannels];\n  const outInNHWCFormat = reshape(\n      {inputs: {x: product}, backend, attrs: {shape: outInNHWCFormatShape}});\n\n  // If the data format is NCHW, then convert the output to be NCHW format.\n  const out = isChannelsLast ?\n      outInNHWCFormat :\n      transpose(\n          {inputs: {x: outInNHWCFormat}, backend, attrs: {perm: [0, 3, 1, 2]}});\n  if (!isChannelsLast) {\n    intermediates.push(outInNHWCFormat);\n  }\n\n  intermediates.push(product);\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n"],"mappings":";AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,IAAI,QAAO,uBAAuB;AAKpE,SAAQC,mBAAmB,QAAO,sBAAsB;AACxD,SAAQC,4BAA4B,QAAO,oCAAoC;AAC/E,SAAQC,mBAAmB,QAAO,sBAAsB;AACxD,OAAO,KAAKC,UAAU,MAAM,eAAe;AAE3C,SAAQC,eAAe,EAAEC,2BAA2B,QAAO,oBAAoB;AAC/E,SAAQC,QAAQ,QAAO,YAAY;AACnC,SAAQC,OAAO,QAAO,WAAW;AACjC,SAAQC,SAAS,QAAO,aAAa;AAarC;AACA;AACA;AACA,OAAM,SAAUC,cAAcA,CAAC;EAC7BC,CAAC;EACDC,MAAM;EACNC,QAAQ;EACRC,OAAO;EACPC,IAAI,GAAG,IAAI;EACXC,sBAAsB,GAAG,IAAI;EAC7BC,cAAc,GAAG,CAAC;EAClBC,UAAU,GAAG;AAAI,CACJ;EACb;EACA;EACA,MAAMC,MAAM,GAAGR,CAAC,CAACS,KAAK;EACtB,MAAMC,QAAQ,GAAGP,OAAO,CAACQ,OAAO,CAACC,GAAG,CAACZ,CAAC,CAACa,MAAM,CAAC;EAC9C,MAAMC,eAAe,GAAGZ,QAAQ,CAACa,UAAU;EAC3C,MAAMC,WAAW,GAAGR,MAAM,CAAC,CAAC,CAAC,GAAGA,MAAM,CAAC,CAAC,CAAC,GAAGA,MAAM,CAAC,CAAC,CAAC;EACrD,MAAMS,gBAAgB,GAAGf,QAAQ,CAACgB,WAAW;EAC7C,MAAMC,cAAc,GAAGjB,QAAQ,CAACkB,UAAU,KAAK,cAAc;EAC7D,MAAMC,UAAU,GAAG,KAAK;EACxB,MAAMC,UAAU,GAAG,KAAK;EAExB,IAAIC,GAAe;EACnB,MAAMC,aAAa,GAAiB,EAAE;EAEtC,IAAInB,sBAAsB,IAAI,IAAI,IAAI,CAACc,cAAc,IACjDd,sBAAsB,CAACI,KAAK,CAACgB,MAAM,KAAK,CAAC,EAAE;IAC7C;IACA;IACA,MAAMC,kCAAkC,GAAG5B,SAAS,CAAC;MACnD6B,MAAM,EAAE;QAAC3B,CAAC,EAAEK;MAAsB,CAAC;MACnCF,OAAO;MACPyB,KAAK,EAAE;QAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;MAAC;KACxB,CAAC;IACFL,aAAa,CAACM,IAAI,CAACJ,kCAAkC,CAAC;IACtDrB,sBAAsB,GAAGqB,kCAAkC;;EAG7D;EACA;EACA,MAAMK,yBAAyB,GAC3B,CAACf,WAAW,KAAK,CAAC,IAAIC,gBAAgB,KAAK,CAAC,KAC5CH,eAAe,GAAGnB,2BAA2B;EAEjD;EACA;EACA;EACA;EACA,MAAMqC,WAAW,GAAG,CAACD,yBAAyB,IAAIrB,QAAQ,CAACuB,QAAQ,IAC/Dd,cAAc,IAAIT,QAAQ,CAACwB,OAAO,IAAI,IAAI,IAAI1B,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IACjEnB,IAAI,CAAC8C,WAAW,CAACzB,QAAQ,CAACD,KAAK,CAAC2B,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE5B,MAAM,CAAC4B,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;EAEhE,IAAIJ,WAAW,EAAE;IACf;IACA;IACA;IACA;IACA;IACA;IACA,MAAMK,WAAW,GAAG7B,MAAM,CAAC,CAAC,CAAC,GAAGA,MAAM,CAAC,CAAC,CAAC,IAAIA,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;IAC3D,MAAM8B,SAAS,GAAe;MAC5BzB,MAAM,EAAEb,CAAC,CAACa,MAAM;MAChBJ,KAAK,EAAE,CAAC,CAAC,EAAE4B,WAAW,EAAEnC,QAAQ,CAACa,UAAU,CAAC;MAC5CwB,KAAK,EAAEvC,CAAC,CAACuC;KACV;IACD;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAMC,qBAAqB,GAAG9B,QAAQ,CAACD,KAAK;IAC5CC,QAAQ,CAACD,KAAK,GAAGC,QAAQ,CAACD,KAAK,CAAC2B,KAAK,EAAE;IACvC1B,QAAQ,CAACD,KAAK,CAACC,QAAQ,CAACD,KAAK,CAACgB,MAAM,GAAG,CAAC,CAAC,EAAE;IAC3CpC,IAAI,CAACoD,MAAM,CACPhD,UAAU,CAACiD,aAAa,CAAChC,QAAQ,CAACD,KAAK,EAAE6B,SAAS,CAAC7B,KAAK,CAAC,EACzD,MAAM,kBAAkBC,QAAQ,CAACD,KAAK,OAClC6B,SAAS,CAAC7B,KAAK,aAAa,CAAC;IACrC,MAAMkC,cAAc,GAAG9C,OAAO,CAAC;MAC7B8B,MAAM,EAAE;QAAC3B,CAAC,EAAEC;MAAM,CAAC;MACnBE,OAAO;MACPyB,KAAK,EAAE;QAACnB,KAAK,EAAE,CAAC,CAAC,EAAEP,QAAQ,CAACa,UAAU,EAAEb,QAAQ,CAACgB,WAAW;MAAC;KAC9D,CAAC;IACFM,aAAa,CAACM,IAAI,CAACa,cAAc,CAAC;IAClC,MAAMC,aAAa,GAAGlD,eAAe,CAAC;MACpCmD,CAAC,EAAEP,SAAS;MACZQ,CAAC,EAAEH,cAAc;MACjBxC,OAAO;MACPkB,UAAU;MACVC,UAAU;MACVlB,IAAI;MACJG,UAAU;MACVF,sBAAsB;MACtBC;KACD,CAAC;IAEF,MAAMyC,oBAAoB,GAAG5C,OAAO,CAACQ,OAAO,CAACC,GAAG,CAACgC,aAAa,CAAC/B,MAAM,CAAC;IACtExB,IAAI,CAACoD,MAAM,CACPM,oBAAoB,CAACd,QAAQ,EAC7B,MAAM,6CAA6C,CAAC;IACxD;IACAvB,QAAQ,CAACD,KAAK,GAAG+B,qBAAqB;IACtC;IACA;IACAO,oBAAoB,CAACtC,KAAK,GAAGP,QAAQ,CAAC8C,QAAQ;IAE9CzB,GAAG,GAAG3B,QAAQ,CAAC;MAAC+B,MAAM,EAAE;QAAC3B,CAAC,EAAE4C;MAAa,CAAC;MAAEzC;IAAO,CAAC,CAAC;IACrDoB,GAAG,CAACd,KAAK,GAAGP,QAAQ,CAAC8C,QAAQ;IAE7BxB,aAAa,CAACM,IAAI,CAACc,aAAa,CAAC;GAClC,MAAM;IACL,MAAMK,aAAa,GAAG9B,cAAc,GAChCnB,CAAC,GACDF,SAAS,CAAC;MAAC6B,MAAM,EAAE;QAAC3B;MAAC,CAAC;MAAEG,OAAO;MAAEyB,KAAK,EAAE;QAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC;MAAC;IAAC,CAAC,CAAC;IAClE,MAAMqB,kBAAkB,GAAGD,aAAa,CAACxC,KAAK;IAC9C,MAAM4B,WAAW,GACba,kBAAkB,CAAC,CAAC,CAAC,GAAGA,kBAAkB,CAAC,CAAC,CAAC,GAAGA,kBAAkB,CAAC,CAAC,CAAC;IACzE,MAAMZ,SAAS,GAAGzC,OAAO,CAAC;MACxB8B,MAAM,EAAE;QAAC3B,CAAC,EAAEiD;MAAa,CAAC;MAC1B9C,OAAO;MACPyB,KAAK,EAAE;QAACnB,KAAK,EAAE,CAAC,CAAC,EAAE4B,WAAW,EAAEnC,QAAQ,CAACa,UAAU;MAAC;KACrD,CAAC;IACF,MAAM4B,cAAc,GAAG9C,OAAO,CAAC;MAC7B8B,MAAM,EAAE;QAAC3B,CAAC,EAAEC;MAAM,CAAC;MACnBE,OAAO;MACPyB,KAAK,EAAE;QAACnB,KAAK,EAAE,CAAC,CAAC,EAAEP,QAAQ,CAACa,UAAU,EAAEb,QAAQ,CAACgB,WAAW;MAAC;KAC9D,CAAC;IACF,MAAMiC,MAAM,GAAGzD,eAAe,CAAC;MAC7BmD,CAAC,EAAEP,SAAS;MACZQ,CAAC,EAAEH,cAAc;MACjBtB,UAAU;MACVC,UAAU;MACVnB,OAAO;MACPC,IAAI;MACJG,UAAU;MACVF,sBAAsB;MACtBC;KACD,CAAC;IAEF,MAAM8C,oBAAoB,GAAG,CAC3BlD,QAAQ,CAACmD,SAAS,EAAEnD,QAAQ,CAACoD,SAAS,EAAEpD,QAAQ,CAACqD,QAAQ,EACzDrD,QAAQ,CAACgB,WAAW,CACrB;IACD,MAAMsC,eAAe,GAAG3D,OAAO,CAC3B;MAAC8B,MAAM,EAAE;QAAC3B,CAAC,EAAEmD;MAAM,CAAC;MAAEhD,OAAO;MAAEyB,KAAK,EAAE;QAACnB,KAAK,EAAE2C;MAAoB;IAAC,CAAC,CAAC;IAEzE;IACA7B,GAAG,GAAGJ,cAAc,GAAGqC,eAAe,GAAG1D,SAAS,CAAC;MACjD6B,MAAM,EAAE;QAAC3B,CAAC,EAAEwD;MAAe,CAAC;MAC5BrD,OAAO;MACPyB,KAAK,EAAE;QAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC;MAAC;KAC3B,CAAC;IACF,IAAI,CAACV,cAAc,EAAE;MACnBK,aAAa,CAACM,IAAI,CAACmB,aAAa,CAAC;MACjCzB,aAAa,CAACM,IAAI,CAAC0B,eAAe,CAAC;;IAGrChC,aAAa,CAACM,IAAI,CAACQ,SAAS,CAAC;IAC7Bd,aAAa,CAACM,IAAI,CAACa,cAAc,CAAC;IAClCnB,aAAa,CAACM,IAAI,CAACqB,MAAM,CAAC;;EAG5B,KAAK,MAAMM,CAAC,IAAIjC,aAAa,EAAE;IAC7BrB,OAAO,CAACuD,6BAA6B,CAACD,CAAC,CAAC;;EAG1C,OAAOlC,GAAG;AACZ;AAEA;AACA;AACA,OAAM,SAAUoC,gBAAgBA,CAAC;EAC/B3D,CAAC;EACDC,MAAM;EACNC,QAAQ;EACRC,OAAO;EACPC,IAAI,GAAG,IAAI;EACXC,sBAAsB,GAAG,IAAI;EAC7BC,cAAc,GAAG,CAAC;EAClBC,UAAU,GAAG;AAAI,CACJ;EACb;EACA;EACA;EACA;EACA;EACA;EACA,MAAM;IACJqD,WAAW;IACXC,YAAY;IACZ9C,UAAU;IACVwC,QAAQ;IACRD,SAAS;IACTlC;EAAU,CACX,GAAGlB,QAAQ;EAEZ,MAAMiB,cAAc,GAAGC,UAAU,KAAK,cAAc;EAEpD,MAAM0C,SAAS,GAAGF,WAAW,GAAGC,YAAY,GAAG9C,UAAU;EACzD,MAAMgD,OAAO,GAAGT,SAAS,GAAGC,QAAQ;EACpC,MAAMS,UAAU,GAAG,CAACF,SAAS,EAAEC,OAAO,CAAC;EACvC,MAAM1C,UAAU,GAAG,IAAI;EACvB,MAAMC,UAAU,GAAG,KAAK;EAExB,MAAME,aAAa,GAAiB,EAAE;EAEtC,IAAInB,sBAAsB,IAAI,IAAI,IAAI,CAACc,cAAc,IACjDd,sBAAsB,CAACI,KAAK,CAACgB,MAAM,KAAK,CAAC,EAAE;IAC7C;IACA;IACA,MAAMC,kCAAkC,GAAG5B,SAAS,CAAC;MACnD6B,MAAM,EAAE;QAAC3B,CAAC,EAAEK;MAAsB,CAAC;MACnCF,OAAO;MACPyB,KAAK,EAAE;QAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;MAAC;KACxB,CAAC;IACFL,aAAa,CAACM,IAAI,CAACJ,kCAAkC,CAAC;IACtDrB,sBAAsB,GAAGqB,kCAAkC;;EAG7D,MAAMuC,SAAS,GACXpE,OAAO,CAAC;IAAC8B,MAAM,EAAE;MAAC3B;IAAC,CAAC;IAAEG,OAAO;IAAEyB,KAAK,EAAE;MAACnB,KAAK,EAAET,CAAC,CAACS,KAAK,CAAC2B,KAAK,CAAC,CAAC;IAAC;EAAC,CAAC,CAAC;EACrE,MAAM8B,KAAK,GAAGrE,OAAO,CAAC;IACpB8B,MAAM,EAAE;MAAC3B,CAAC,EAAEC;IAAM,CAAC;IACnBE,OAAO;IACPyB,KAAK,EAAE;MAACnB,KAAK,EAAE,CAAC,CAAC,EAAEqD,SAAS,EAAEzE,IAAI,CAAC8E,aAAa,CAAClE,MAAM,CAACQ,KAAK,CAAC,GAAGqD,SAAS;IAAC;GAC5E,CAAC;EAEFtC,aAAa,CAACM,IAAI,CAACmC,SAAS,CAAC;EAC7BzC,aAAa,CAACM,IAAI,CAACoC,KAAK,CAAC;EAEzB,MAAME,aAAa,GAAG,IAAI9E,mBAAmB,CAAC0E,UAAU,EAAE9D,QAAQ,CAAC;EACnE,MAAMmE,YAAY,GAAG,CACnBJ,SAAS,CAACxD,KAAK,EAAE,CAACP,QAAQ,CAACoE,OAAO,CAACC,GAAG,EAAErE,QAAQ,CAACoE,OAAO,CAACE,IAAI,CAAC,EAC9D,CAACtE,QAAQ,CAACuE,YAAY,EAAEvE,QAAQ,CAACwE,WAAW,CAAC,EAC7C,CAACxE,QAAQ,CAACyE,cAAc,EAAEzE,QAAQ,CAAC0E,aAAa,CAAC,EAAE,CAAC1E,QAAQ,CAACa,UAAU,CAAC,EACxE,CAACb,QAAQ,CAAC0D,WAAW,GAAG1D,QAAQ,CAACa,UAAU,CAAC,EAAE,CAACb,QAAQ,CAACqD,QAAQ,CAAC,CAClE;EACD,MAAMsB,MAAM,GAAG1E,OAAO,CAAC2E,eAAe,CAClCV,aAAa,EAAE,CAACH,SAAS,CAAC,EAAE,SAAS,EAAEI,YAAY,CAAC;EACxD,MAAMU,cAAc,GAAGlF,OAAO,CAAC;IAC7B8B,MAAM,EAAE;MAAC3B,CAAC,EAAE6E;IAAM,CAAC;IACnB1E,OAAO;IACPyB,KAAK,EAAE;MAACnB,KAAK,EAAE,CAAC,CAAC,EAAEuD,UAAU,CAAC,CAAC,CAAC,EAAEA,UAAU,CAAC,CAAC,CAAC;IAAC;GACjD,CAAC;EAEFxC,aAAa,CAACM,IAAI,CAAC+C,MAAM,CAAC;EAC1BrD,aAAa,CAACM,IAAI,CAACiD,cAAc,CAAC;EAElC,MAAMC,OAAO,GAAG5E,IAAI,IAAI,IAAI;EAC5B,MAAM6E,yBAAyB,GAAG5E,sBAAsB,IAAI,IAAI;EAChE,MAAM6E,iBAAiB,GAAG3E,UAAU,KAAK,WAAW;EACpD,MAAM4E,eAAe,GACjB5E,UAAU,GAAGhB,4BAA4B,CAACgB,UAAU,EAAE,IAAI,CAAC,GAAG,IAAI;EACtE,MAAM6E,aAAa,GAAG,IAAI5F,mBAAmB,CACzCuF,cAAc,CAACtE,KAAiC,EAChDyD,KAAK,CAACzD,KAAiC,EACvC,CAAC,CAAC,EAAEsD,OAAO,EAAE7D,QAAQ,CAACgB,WAAW,CAAC,EAAEG,UAAU,EAAEC,UAAU,EAAE0D,OAAO,EACnEG,eAAe,EAAEF,yBAAyB,EAAEC,iBAAiB,CAAC;EAClE,MAAMvD,MAAM,GAAiB,CAACoD,cAAc,EAAEb,KAAK,CAAC;EACpD,IAAI9D,IAAI,EAAE;IACRuB,MAAM,CAACG,IAAI,CAAC1B,IAAI,CAAC;;EAEnB,IAAI6E,yBAAyB,EAAE;IAC7BtD,MAAM,CAACG,IAAI,CAACzB,sBAAsB,CAAC;;EAErC,IAAI6E,iBAAiB,EAAE;IACrB,MAAMG,eAAe,GAAGlF,OAAO,CAACmF,cAAc,CAC1C,EAAE,EAAE,SAAS,EACbjG,IAAI,CAACkG,iBAAiB,CAACjF,cAAiC,EAAE,SAAS,CAAC,CAAC;IACzEqB,MAAM,CAACG,IAAI,CAACuD,eAAe,CAAC;IAC5B7D,aAAa,CAACM,IAAI,CAACuD,eAAe,CAAC;;EAErC,MAAMG,OAAO,GAAGrF,OAAO,CAAC2E,eAAe,CAACM,aAAa,EAAEzD,MAAM,EAAE,SAAS,CAAC;EAEzE,MAAMyB,oBAAoB,GAAG,CAAC,CAAC,EAAEE,SAAS,EAAEC,QAAQ,EAAErD,QAAQ,CAACgB,WAAW,CAAC;EAC3E,MAAMsC,eAAe,GAAG3D,OAAO,CAC3B;IAAC8B,MAAM,EAAE;MAAC3B,CAAC,EAAEwF;IAAO,CAAC;IAAErF,OAAO;IAAEyB,KAAK,EAAE;MAACnB,KAAK,EAAE2C;IAAoB;EAAC,CAAC,CAAC;EAE1E;EACA,MAAM7B,GAAG,GAAGJ,cAAc,GACtBqC,eAAe,GACf1D,SAAS,CACL;IAAC6B,MAAM,EAAE;MAAC3B,CAAC,EAAEwD;IAAe,CAAC;IAAErD,OAAO;IAAEyB,KAAK,EAAE;MAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC;IAAC;EAAC,CAAC,CAAC;EAC7E,IAAI,CAACV,cAAc,EAAE;IACnBK,aAAa,CAACM,IAAI,CAAC0B,eAAe,CAAC;;EAGrChC,aAAa,CAACM,IAAI,CAAC0D,OAAO,CAAC;EAC3B,KAAK,MAAM/B,CAAC,IAAIjC,aAAa,EAAE;IAC7BrB,OAAO,CAACuD,6BAA6B,CAACD,CAAC,CAAC;;EAG1C,OAAOlC,GAAG;AACZ"},"metadata":{},"sourceType":"module","externalDependencies":[]}