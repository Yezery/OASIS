{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedConv2D, util } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function fusedConv2d(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n  let out;\n  const intermediates = [];\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n    out = conv2dWithIm2Row({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else {\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n    const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const inputs = [x, filter];\n    // If the input is a 1-D tensor, align it with the channels.\n    //\n    // For fusedConv2d, the inputs (x, W, bias, preluActivationWeights) are\n    // supposed to be aligned with the dataFormat. The 4-D tensor inputs or\n    // scalar inputs are originally aligned, but the 1-D tensor inputs are\n    // supposed to be aligned with the channels (only bias and PReLU activation\n    // weights could be a 1-D tensor).\n    const alignInputWithDataFormat = (input, dataFormat) => {\n      if (dataFormat === 'NCHW' && input.shape.length === 1 && input.shape[0] !== 1) {\n        const alignedInput = reshape({\n          inputs: {\n            x: input\n          },\n          backend,\n          attrs: {\n            shape: [input.shape[0], 1, 1]\n          }\n        });\n        intermediates.push(alignedInput);\n        return alignedInput;\n      }\n      return input;\n    };\n    if (hasBias) {\n      inputs.push(alignInputWithDataFormat(bias, dataFormat));\n    }\n    if (hasPreluActivationWeights) {\n      inputs.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));\n    }\n    if (hasLeakyreluAlpha) {\n      const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n      inputs.push($leakyreluAlpha);\n      intermediates.push($leakyreluAlpha);\n    }\n    out = backend.runWebGLProgram(program, inputs, 'float32');\n  }\n  const outReshaped = reshape({\n    inputs: {\n      x: out\n    },\n    backend,\n    attrs: {\n      shape: convInfo.outShape\n    }\n  });\n  intermediates.push(out);\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return outReshaped;\n}\nexport const fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d\n};","map":{"version":3,"names":["backend_util","env","FusedConv2D","util","Conv2DProgram","mapActivationToShaderProgram","conv2dByMatMul","conv2dWithIm2Row","reshape","fusedConv2d","args","inputs","backend","attrs","x","filter","bias","preluActivationWeights","strides","pad","dataFormat","dilations","dimRoundingMode","activation","leakyreluAlpha","$dataFormat","convertConv2DDataFormat","convInfo","computeConv2DInfo","shape","out","intermediates","filterHeight","filterWidth","dilationHeight","dilationWidth","strideHeight","strideWidth","padInfo","type","getBool","hasBias","hasPreluActivationWeights","hasLeakyreluAlpha","fusedActivation","program","alignInputWithDataFormat","input","length","alignedInput","push","$leakyreluAlpha","makeTensorInfo","createScalarValue","runWebGLProgram","outReshaped","outShape","forEach","t","disposeIntermediateTensorInfo","fusedConv2DConfig","kernelName","backendName","kernelFunc"],"sources":["../../../../../../tfjs-backend-webgl/src/kernels/FusedConv2D.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {Conv2DProgram} from '../conv_gpu';\nimport {mapActivationToShaderProgram} from '../kernel_utils/kernel_funcs_utils';\n\nimport {conv2dByMatMul, conv2dWithIm2Row} from './Conv2D_impl';\nimport {reshape} from './Reshape';\n\nexport function fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  attrs: FusedConv2DAttrs,\n  backend: MathBackendWebGL\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n  let out: TensorInfo;\n  const intermediates: TensorInfo[] = [];\n\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n      (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n    out = conv2dWithIm2Row({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else {\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    const fusedActivation =\n        activation ? mapActivationToShaderProgram(activation, false) : null;\n    const program = new Conv2DProgram(\n        convInfo, hasBias, fusedActivation, hasPreluActivationWeights,\n        hasLeakyreluAlpha);\n    const inputs: TensorInfo[] = [x, filter];\n\n    // If the input is a 1-D tensor, align it with the channels.\n    //\n    // For fusedConv2d, the inputs (x, W, bias, preluActivationWeights) are\n    // supposed to be aligned with the dataFormat. The 4-D tensor inputs or\n    // scalar inputs are originally aligned, but the 1-D tensor inputs are\n    // supposed to be aligned with the channels (only bias and PReLU activation\n    // weights could be a 1-D tensor).\n    const alignInputWithDataFormat =\n        (input: TensorInfo, dataFormat: 'NHWC'|'NCHW'): TensorInfo => {\n          if (dataFormat === 'NCHW' && input.shape.length === 1 &&\n              input.shape[0] !== 1) {\n            const alignedInput = reshape({\n              inputs: {x: input},\n              backend,\n              attrs: {shape: [input.shape[0], 1, 1]}\n            });\n            intermediates.push(alignedInput);\n            return alignedInput;\n          }\n          return input;\n        };\n\n    if (hasBias) {\n      inputs.push(alignInputWithDataFormat(bias, dataFormat));\n    }\n\n    if (hasPreluActivationWeights) {\n      inputs.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));\n    }\n\n    if (hasLeakyreluAlpha) {\n      const $leakyreluAlpha = backend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(leakyreluAlpha as {} as 'float32', 'float32'));\n      inputs.push($leakyreluAlpha);\n      intermediates.push($leakyreluAlpha);\n    }\n    out = backend.runWebGLProgram(program, inputs, 'float32');\n  }\n\n  const outReshaped =\n      reshape({inputs: {x: out}, backend, attrs: {shape: convInfo.outShape}});\n\n  intermediates.push(out);\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outReshaped;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d as {} as KernelFunc,\n};\n"],"mappings":";AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAAEC,GAAG,EAAEC,WAAW,EAA6EC,IAAI,QAAO,uBAAuB;AAGrJ,SAAQC,aAAa,QAAO,aAAa;AACzC,SAAQC,4BAA4B,QAAO,oCAAoC;AAE/E,SAAQC,cAAc,EAAEC,gBAAgB,QAAO,eAAe;AAC9D,SAAQC,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAUC,WAAWA,CAACC,IAI3B;EACC,MAAM;IAACC,MAAM;IAAEC,OAAO;IAAEC;EAAK,CAAC,GAAGH,IAAI;EACrC,MAAM;IAACI,CAAC;IAAEC,MAAM;IAAEC,IAAI;IAAEC;EAAsB,CAAC,GAAGN,MAAM;EACxD,MAAM;IACJO,OAAO;IACPC,GAAG;IACHC,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC,UAAU;IACVC;EAAc,CACf,GAAGX,KAAK;EAET,MAAMY,WAAW,GAAGzB,YAAY,CAAC0B,uBAAuB,CAACN,UAAU,CAAC;EACpE,MAAMO,QAAQ,GAAG3B,YAAY,CAAC4B,iBAAiB,CAC3Cd,CAAC,CAACe,KAAyC,EAC3Cd,MAAM,CAACc,KAAyC,EAAEX,OAAO,EAAEG,SAAS,EAAEF,GAAG,EACzEG,eAAe,EAAE,KAAK,CAAC,iBAAiBG,WAAW,CAAC;EACxD,IAAIK,GAAe;EACnB,MAAMC,aAAa,GAAiB,EAAE;EAEtC,IAAIJ,QAAQ,CAACK,YAAY,KAAK,CAAC,IAAIL,QAAQ,CAACM,WAAW,KAAK,CAAC,IACzDN,QAAQ,CAACO,cAAc,KAAK,CAAC,IAAIP,QAAQ,CAACQ,aAAa,KAAK,CAAC,IAC7DR,QAAQ,CAACS,YAAY,KAAK,CAAC,IAAIT,QAAQ,CAACU,WAAW,KAAK,CAAC,KACxDV,QAAQ,CAACW,OAAO,CAACC,IAAI,KAAK,MAAM,IAAIZ,QAAQ,CAACW,OAAO,CAACC,IAAI,KAAK,OAAO,CAAC,EAAE;IAC3ET,GAAG,GAAGxB,cAAc,CAAC;MACnBQ,CAAC;MACDC,MAAM;MACNY,QAAQ;MACRf,OAAO;MACPI,IAAI;MACJO,UAAU;MACVN,sBAAsB;MACtBO;KACD,CAAC;GACH,MAAM,IAAIvB,GAAG,EAAE,CAACuC,OAAO,CAAC,mBAAmB,CAAC,IAAI1B,CAAC,CAACe,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;IACjEC,GAAG,GAAGvB,gBAAgB,CAAC;MACrBO,CAAC;MACDC,MAAM;MACNY,QAAQ;MACRf,OAAO;MACPI,IAAI;MACJO,UAAU;MACVN,sBAAsB;MACtBO;KACD,CAAC;GACH,MAAM;IACL,MAAMiB,OAAO,GAAGzB,IAAI,IAAI,IAAI;IAC5B,MAAM0B,yBAAyB,GAAGzB,sBAAsB,IAAI,IAAI;IAChE,MAAM0B,iBAAiB,GAAGpB,UAAU,KAAK,WAAW;IACpD,MAAMqB,eAAe,GACjBrB,UAAU,GAAGlB,4BAA4B,CAACkB,UAAU,EAAE,KAAK,CAAC,GAAG,IAAI;IACvE,MAAMsB,OAAO,GAAG,IAAIzC,aAAa,CAC7BuB,QAAQ,EAAEc,OAAO,EAAEG,eAAe,EAAEF,yBAAyB,EAC7DC,iBAAiB,CAAC;IACtB,MAAMhC,MAAM,GAAiB,CAACG,CAAC,EAAEC,MAAM,CAAC;IAExC;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAM+B,wBAAwB,GAC1BA,CAACC,KAAiB,EAAE3B,UAAyB,KAAgB;MAC3D,IAAIA,UAAU,KAAK,MAAM,IAAI2B,KAAK,CAAClB,KAAK,CAACmB,MAAM,KAAK,CAAC,IACjDD,KAAK,CAAClB,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;QACxB,MAAMoB,YAAY,GAAGzC,OAAO,CAAC;UAC3BG,MAAM,EAAE;YAACG,CAAC,EAAEiC;UAAK,CAAC;UAClBnC,OAAO;UACPC,KAAK,EAAE;YAACgB,KAAK,EAAE,CAACkB,KAAK,CAAClB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;UAAC;SACtC,CAAC;QACFE,aAAa,CAACmB,IAAI,CAACD,YAAY,CAAC;QAChC,OAAOA,YAAY;;MAErB,OAAOF,KAAK;IACd,CAAC;IAEL,IAAIN,OAAO,EAAE;MACX9B,MAAM,CAACuC,IAAI,CAACJ,wBAAwB,CAAC9B,IAAI,EAAEI,UAAU,CAAC,CAAC;;IAGzD,IAAIsB,yBAAyB,EAAE;MAC7B/B,MAAM,CAACuC,IAAI,CAACJ,wBAAwB,CAAC7B,sBAAsB,EAAEG,UAAU,CAAC,CAAC;;IAG3E,IAAIuB,iBAAiB,EAAE;MACrB,MAAMQ,eAAe,GAAGvC,OAAO,CAACwC,cAAc,CAC1C,EAAE,EAAE,SAAS,EACbjD,IAAI,CAACkD,iBAAiB,CAAC7B,cAAiC,EAAE,SAAS,CAAC,CAAC;MACzEb,MAAM,CAACuC,IAAI,CAACC,eAAe,CAAC;MAC5BpB,aAAa,CAACmB,IAAI,CAACC,eAAe,CAAC;;IAErCrB,GAAG,GAAGlB,OAAO,CAAC0C,eAAe,CAACT,OAAO,EAAElC,MAAM,EAAE,SAAS,CAAC;;EAG3D,MAAM4C,WAAW,GACb/C,OAAO,CAAC;IAACG,MAAM,EAAE;MAACG,CAAC,EAAEgB;IAAG,CAAC;IAAElB,OAAO;IAAEC,KAAK,EAAE;MAACgB,KAAK,EAAEF,QAAQ,CAAC6B;IAAQ;EAAC,CAAC,CAAC;EAE3EzB,aAAa,CAACmB,IAAI,CAACpB,GAAG,CAAC;EACvBC,aAAa,CAAC0B,OAAO,CAACC,CAAC,IAAI9C,OAAO,CAAC+C,6BAA6B,CAACD,CAAC,CAAC,CAAC;EAEpE,OAAOH,WAAW;AACpB;AAEA,OAAO,MAAMK,iBAAiB,GAAiB;EAC7CC,UAAU,EAAE3D,WAAW;EACvB4D,WAAW,EAAE,OAAO;EACpBC,UAAU,EAAEtD;CACb"},"metadata":{},"sourceType":"module","externalDependencies":[]}