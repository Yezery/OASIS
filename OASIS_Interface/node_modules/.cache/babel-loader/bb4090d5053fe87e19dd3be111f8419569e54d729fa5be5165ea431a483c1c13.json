{"ast":null,"code":"import \"core-js/modules/es.typed-array.to-reversed.js\";\nimport \"core-js/modules/es.typed-array.to-sorted.js\";\nimport \"core-js/modules/es.typed-array.with.js\";\nimport \"core-js/modules/es.array.push.js\";\nimport extractDataFromBlock from '../../../utils/extract-data-from-block.js';\nimport validateOffsetAndLength from '../../../utils/validate-offset-and-length.js';\nimport { UnixFS } from 'ipfs-unixfs';\nimport errCode from 'err-code';\nimport * as dagPb from '@ipld/dag-pb';\nimport * as raw from 'multiformats/codecs/raw';\nimport { pushable } from 'it-pushable';\nimport parallel from 'it-parallel';\nimport { pipe } from 'it-pipe';\nimport map from 'it-map';\nimport PQueue from 'p-queue';\n\n/**\n * @typedef {import('../../../types').ExporterOptions} ExporterOptions\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {Blockstore} blockstore\n * @param {PBNode | Uint8Array} node\n * @param {import('it-pushable').Pushable<Uint8Array>} queue\n * @param {number} streamPosition\n * @param {number} start\n * @param {number} end\n * @param {PQueue} walkQueue\n * @param {ExporterOptions} options\n * @returns {Promise<void>}\n */\nasync function walkDAG(blockstore, node, queue, streamPosition, start, end, walkQueue, options) {\n  // a `raw` node\n  if (node instanceof Uint8Array) {\n    queue.push(extractDataFromBlock(node, streamPosition, start, end));\n    return;\n  }\n  if (node.Data == null) {\n    throw errCode(new Error('no data in PBNode'), 'ERR_NOT_UNIXFS');\n  }\n\n  /** @type {UnixFS} */\n  let file;\n  try {\n    file = UnixFS.unmarshal(node.Data);\n  } catch ( /** @type {any} */err) {\n    throw errCode(err, 'ERR_NOT_UNIXFS');\n  }\n\n  // might be a unixfs `raw` node or have data on intermediate nodes\n  if (file.data != null) {\n    const data = file.data;\n    const buf = extractDataFromBlock(data, streamPosition, start, end);\n    queue.push(buf);\n    streamPosition += buf.byteLength;\n  }\n\n  /** @type {Array<{ link: PBLink, blockStart: number }>} */\n  const childOps = [];\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i];\n    const childStart = streamPosition; // inclusive\n    const childEnd = childStart + file.blockSizes[i]; // exclusive\n\n    if (start >= childStart && start < childEnd ||\n    // child has offset byte\n    end >= childStart && end <= childEnd ||\n    // child has end byte\n    start < childStart && end > childEnd) {\n      // child is between offset and end bytes\n      childOps.push({\n        link: childLink,\n        blockStart: streamPosition\n      });\n    }\n    streamPosition = childEnd;\n    if (streamPosition > end) {\n      break;\n    }\n  }\n  await pipe(childOps, source => map(source, op => {\n    return async () => {\n      const block = await blockstore.get(op.link.Hash, {\n        signal: options.signal\n      });\n      return {\n        ...op,\n        block\n      };\n    };\n  }), source => parallel(source, {\n    ordered: true\n  }), async source => {\n    for await (const {\n      link,\n      block,\n      blockStart\n    } of source) {\n      /** @type {PBNode | Uint8Array} */\n      let child;\n      switch (link.Hash.code) {\n        case dagPb.code:\n          child = dagPb.decode(block);\n          break;\n        case raw.code:\n          child = block;\n          break;\n        default:\n          queue.end(errCode(new Error(`Unsupported codec: ${link.Hash.code}`), 'ERR_NOT_UNIXFS'));\n          return;\n      }\n      walkQueue.add(async () => {\n        await walkDAG(blockstore, child, queue, blockStart, start, end, walkQueue, options);\n      });\n    }\n  });\n}\n\n/**\n * @type {import('../').UnixfsV1Resolver}\n */\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  /**\n   * @param {ExporterOptions} options\n   */\n  async function* yieldFileContent(options = {}) {\n    const fileSize = unixfs.fileSize();\n    if (fileSize === undefined) {\n      throw new Error('File was a directory');\n    }\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length);\n    if (length === 0) {\n      return;\n    }\n\n    // use a queue to walk the DAG instead of recursion to ensure very deep DAGs\n    // don't overflow the stack\n    const walkQueue = new PQueue({\n      concurrency: 1\n    });\n    const queue = pushable();\n    walkQueue.add(async () => {\n      await walkDAG(blockstore, node, queue, 0, offset, offset + length, walkQueue, options);\n    });\n    walkQueue.on('error', error => {\n      queue.end(error);\n    });\n    let read = 0;\n    for await (const buf of queue) {\n      if (buf == null) {\n        continue;\n      }\n      read += buf.byteLength;\n      if (read === length) {\n        queue.end();\n      }\n      yield buf;\n    }\n  }\n  return yieldFileContent;\n};\nexport default fileContent;","map":{"version":3,"names":["extractDataFromBlock","validateOffsetAndLength","UnixFS","errCode","dagPb","raw","pushable","parallel","pipe","map","PQueue","walkDAG","blockstore","node","queue","streamPosition","start","end","walkQueue","options","Uint8Array","push","Data","Error","file","unmarshal","err","data","buf","byteLength","childOps","i","Links","length","childLink","childStart","childEnd","blockSizes","link","blockStart","source","op","block","get","Hash","signal","ordered","child","code","decode","add","fileContent","cid","unixfs","path","resolve","depth","yieldFileContent","fileSize","undefined","offset","concurrency","on","error","read"],"sources":["/Users/yezery/Oasis/OASIS/node_modules/.store/ipfs-unixfs-exporter@10.0.1/node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/content/file.js"],"sourcesContent":["import extractDataFromBlock from '../../../utils/extract-data-from-block.js'\nimport validateOffsetAndLength from '../../../utils/validate-offset-and-length.js'\nimport { UnixFS } from 'ipfs-unixfs'\nimport errCode from 'err-code'\nimport * as dagPb from '@ipld/dag-pb'\nimport * as raw from 'multiformats/codecs/raw'\nimport { pushable } from 'it-pushable'\nimport parallel from 'it-parallel'\nimport { pipe } from 'it-pipe'\nimport map from 'it-map'\nimport PQueue from 'p-queue'\n\n/**\n * @typedef {import('../../../types').ExporterOptions} ExporterOptions\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {Blockstore} blockstore\n * @param {PBNode | Uint8Array} node\n * @param {import('it-pushable').Pushable<Uint8Array>} queue\n * @param {number} streamPosition\n * @param {number} start\n * @param {number} end\n * @param {PQueue} walkQueue\n * @param {ExporterOptions} options\n * @returns {Promise<void>}\n */\nasync function walkDAG (blockstore, node, queue, streamPosition, start, end, walkQueue, options) {\n  // a `raw` node\n  if (node instanceof Uint8Array) {\n    queue.push(extractDataFromBlock(node, streamPosition, start, end))\n\n    return\n  }\n\n  if (node.Data == null) {\n    throw errCode(new Error('no data in PBNode'), 'ERR_NOT_UNIXFS')\n  }\n\n  /** @type {UnixFS} */\n  let file\n\n  try {\n    file = UnixFS.unmarshal(node.Data)\n  } catch (/** @type {any} */ err) {\n    throw errCode(err, 'ERR_NOT_UNIXFS')\n  }\n\n  // might be a unixfs `raw` node or have data on intermediate nodes\n  if (file.data != null) {\n    const data = file.data\n    const buf = extractDataFromBlock(data, streamPosition, start, end)\n\n    queue.push(buf)\n\n    streamPosition += buf.byteLength\n  }\n\n  /** @type {Array<{ link: PBLink, blockStart: number }>} */\n  const childOps = []\n\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i]\n    const childStart = streamPosition // inclusive\n    const childEnd = childStart + file.blockSizes[i] // exclusive\n\n    if ((start >= childStart && start < childEnd) || // child has offset byte\n        (end >= childStart && end <= childEnd) || // child has end byte\n        (start < childStart && end > childEnd)) { // child is between offset and end bytes\n      childOps.push({\n        link: childLink,\n        blockStart: streamPosition\n      })\n    }\n\n    streamPosition = childEnd\n\n    if (streamPosition > end) {\n      break\n    }\n  }\n\n  await pipe(\n    childOps,\n    (source) => map(source, (op) => {\n      return async () => {\n        const block = await blockstore.get(op.link.Hash, {\n          signal: options.signal\n        })\n\n        return {\n          ...op,\n          block\n        }\n      }\n    }),\n    (source) => parallel(source, {\n      ordered: true\n    }),\n    async (source) => {\n      for await (const { link, block, blockStart } of source) {\n        /** @type {PBNode | Uint8Array} */\n        let child\n        switch (link.Hash.code) {\n          case dagPb.code:\n            child = dagPb.decode(block)\n            break\n          case raw.code:\n            child = block\n            break\n          default:\n            queue.end(errCode(new Error(`Unsupported codec: ${link.Hash.code}`), 'ERR_NOT_UNIXFS'))\n            return\n        }\n\n        walkQueue.add(async () => {\n          await walkDAG(blockstore, child, queue, blockStart, start, end, walkQueue, options)\n        })\n      }\n    }\n  )\n}\n\n/**\n * @type {import('../').UnixfsV1Resolver}\n */\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  /**\n   * @param {ExporterOptions} options\n   */\n  async function * yieldFileContent (options = {}) {\n    const fileSize = unixfs.fileSize()\n\n    if (fileSize === undefined) {\n      throw new Error('File was a directory')\n    }\n\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length)\n\n    if (length === 0) {\n      return\n    }\n\n    // use a queue to walk the DAG instead of recursion to ensure very deep DAGs\n    // don't overflow the stack\n    const walkQueue = new PQueue({\n      concurrency: 1\n    })\n    const queue = pushable()\n\n    walkQueue.add(async () => {\n      await walkDAG(blockstore, node, queue, 0, offset, offset + length, walkQueue, options)\n    })\n\n    walkQueue.on('error', error => {\n      queue.end(error)\n    })\n\n    let read = 0\n\n    for await (const buf of queue) {\n      if (buf == null) {\n        continue\n      }\n\n      read += buf.byteLength\n\n      if (read === length) {\n        queue.end()\n      }\n\n      yield buf\n    }\n  }\n\n  return yieldFileContent\n}\n\nexport default fileContent\n"],"mappings":";;;;AAAA,OAAOA,oBAAoB,MAAM,2CAA2C;AAC5E,OAAOC,uBAAuB,MAAM,8CAA8C;AAClF,SAASC,MAAM,QAAQ,aAAa;AACpC,OAAOC,OAAO,MAAM,UAAU;AAC9B,OAAO,KAAKC,KAAK,MAAM,cAAc;AACrC,OAAO,KAAKC,GAAG,MAAM,yBAAyB;AAC9C,SAASC,QAAQ,QAAQ,aAAa;AACtC,OAAOC,QAAQ,MAAM,aAAa;AAClC,SAASC,IAAI,QAAQ,SAAS;AAC9B,OAAOC,GAAG,MAAM,QAAQ;AACxB,OAAOC,MAAM,MAAM,SAAS;;AAE5B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeC,OAAOA,CAAEC,UAAU,EAAEC,IAAI,EAAEC,KAAK,EAAEC,cAAc,EAAEC,KAAK,EAAEC,GAAG,EAAEC,SAAS,EAAEC,OAAO,EAAE;EAC/F;EACA,IAAIN,IAAI,YAAYO,UAAU,EAAE;IAC9BN,KAAK,CAACO,IAAI,CAACrB,oBAAoB,CAACa,IAAI,EAAEE,cAAc,EAAEC,KAAK,EAAEC,GAAG,CAAC,CAAC;IAElE;EACF;EAEA,IAAIJ,IAAI,CAACS,IAAI,IAAI,IAAI,EAAE;IACrB,MAAMnB,OAAO,CAAC,IAAIoB,KAAK,CAAC,mBAAmB,CAAC,EAAE,gBAAgB,CAAC;EACjE;;EAEA;EACA,IAAIC,IAAI;EAER,IAAI;IACFA,IAAI,GAAGtB,MAAM,CAACuB,SAAS,CAACZ,IAAI,CAACS,IAAI,CAAC;EACpC,CAAC,CAAC,QAAO,kBAAmBI,GAAG,EAAE;IAC/B,MAAMvB,OAAO,CAACuB,GAAG,EAAE,gBAAgB,CAAC;EACtC;;EAEA;EACA,IAAIF,IAAI,CAACG,IAAI,IAAI,IAAI,EAAE;IACrB,MAAMA,IAAI,GAAGH,IAAI,CAACG,IAAI;IACtB,MAAMC,GAAG,GAAG5B,oBAAoB,CAAC2B,IAAI,EAAEZ,cAAc,EAAEC,KAAK,EAAEC,GAAG,CAAC;IAElEH,KAAK,CAACO,IAAI,CAACO,GAAG,CAAC;IAEfb,cAAc,IAAIa,GAAG,CAACC,UAAU;EAClC;;EAEA;EACA,MAAMC,QAAQ,GAAG,EAAE;EAEnB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlB,IAAI,CAACmB,KAAK,CAACC,MAAM,EAAEF,CAAC,EAAE,EAAE;IAC1C,MAAMG,SAAS,GAAGrB,IAAI,CAACmB,KAAK,CAACD,CAAC,CAAC;IAC/B,MAAMI,UAAU,GAAGpB,cAAc,EAAC;IAClC,MAAMqB,QAAQ,GAAGD,UAAU,GAAGX,IAAI,CAACa,UAAU,CAACN,CAAC,CAAC,EAAC;;IAEjD,IAAKf,KAAK,IAAImB,UAAU,IAAInB,KAAK,GAAGoB,QAAQ;IAAK;IAC5CnB,GAAG,IAAIkB,UAAU,IAAIlB,GAAG,IAAImB,QAAS;IAAI;IACzCpB,KAAK,GAAGmB,UAAU,IAAIlB,GAAG,GAAGmB,QAAS,EAAE;MAAE;MAC5CN,QAAQ,CAACT,IAAI,CAAC;QACZiB,IAAI,EAAEJ,SAAS;QACfK,UAAU,EAAExB;MACd,CAAC,CAAC;IACJ;IAEAA,cAAc,GAAGqB,QAAQ;IAEzB,IAAIrB,cAAc,GAAGE,GAAG,EAAE;MACxB;IACF;EACF;EAEA,MAAMT,IAAI,CACRsB,QAAQ,EACPU,MAAM,IAAK/B,GAAG,CAAC+B,MAAM,EAAGC,EAAE,IAAK;IAC9B,OAAO,YAAY;MACjB,MAAMC,KAAK,GAAG,MAAM9B,UAAU,CAAC+B,GAAG,CAACF,EAAE,CAACH,IAAI,CAACM,IAAI,EAAE;QAC/CC,MAAM,EAAE1B,OAAO,CAAC0B;MAClB,CAAC,CAAC;MAEF,OAAO;QACL,GAAGJ,EAAE;QACLC;MACF,CAAC;IACH,CAAC;EACH,CAAC,CAAC,EACDF,MAAM,IAAKjC,QAAQ,CAACiC,MAAM,EAAE;IAC3BM,OAAO,EAAE;EACX,CAAC,CAAC,EACF,MAAON,MAAM,IAAK;IAChB,WAAW,MAAM;MAAEF,IAAI;MAAEI,KAAK;MAAEH;IAAW,CAAC,IAAIC,MAAM,EAAE;MACtD;MACA,IAAIO,KAAK;MACT,QAAQT,IAAI,CAACM,IAAI,CAACI,IAAI;QACpB,KAAK5C,KAAK,CAAC4C,IAAI;UACbD,KAAK,GAAG3C,KAAK,CAAC6C,MAAM,CAACP,KAAK,CAAC;UAC3B;QACF,KAAKrC,GAAG,CAAC2C,IAAI;UACXD,KAAK,GAAGL,KAAK;UACb;QACF;UACE5B,KAAK,CAACG,GAAG,CAACd,OAAO,CAAC,IAAIoB,KAAK,CAAE,sBAAqBe,IAAI,CAACM,IAAI,CAACI,IAAK,EAAC,CAAC,EAAE,gBAAgB,CAAC,CAAC;UACvF;MACJ;MAEA9B,SAAS,CAACgC,GAAG,CAAC,YAAY;QACxB,MAAMvC,OAAO,CAACC,UAAU,EAAEmC,KAAK,EAAEjC,KAAK,EAAEyB,UAAU,EAAEvB,KAAK,EAAEC,GAAG,EAAEC,SAAS,EAAEC,OAAO,CAAC;MACrF,CAAC,CAAC;IACJ;EACF,CACF,CAAC;AACH;;AAEA;AACA;AACA;AACA,MAAMgC,WAAW,GAAGA,CAACC,GAAG,EAAEvC,IAAI,EAAEwC,MAAM,EAAEC,IAAI,EAAEC,OAAO,EAAEC,KAAK,EAAE5C,UAAU,KAAK;EAC3E;AACF;AACA;EACE,gBAAiB6C,gBAAgBA,CAAEtC,OAAO,GAAG,CAAC,CAAC,EAAE;IAC/C,MAAMuC,QAAQ,GAAGL,MAAM,CAACK,QAAQ,CAAC,CAAC;IAElC,IAAIA,QAAQ,KAAKC,SAAS,EAAE;MAC1B,MAAM,IAAIpC,KAAK,CAAC,sBAAsB,CAAC;IACzC;IAEA,MAAM;MACJqC,MAAM;MACN3B;IACF,CAAC,GAAGhC,uBAAuB,CAACyD,QAAQ,EAAEvC,OAAO,CAACyC,MAAM,EAAEzC,OAAO,CAACc,MAAM,CAAC;IAErE,IAAIA,MAAM,KAAK,CAAC,EAAE;MAChB;IACF;;IAEA;IACA;IACA,MAAMf,SAAS,GAAG,IAAIR,MAAM,CAAC;MAC3BmD,WAAW,EAAE;IACf,CAAC,CAAC;IACF,MAAM/C,KAAK,GAAGR,QAAQ,CAAC,CAAC;IAExBY,SAAS,CAACgC,GAAG,CAAC,YAAY;MACxB,MAAMvC,OAAO,CAACC,UAAU,EAAEC,IAAI,EAAEC,KAAK,EAAE,CAAC,EAAE8C,MAAM,EAAEA,MAAM,GAAG3B,MAAM,EAAEf,SAAS,EAAEC,OAAO,CAAC;IACxF,CAAC,CAAC;IAEFD,SAAS,CAAC4C,EAAE,CAAC,OAAO,EAAEC,KAAK,IAAI;MAC7BjD,KAAK,CAACG,GAAG,CAAC8C,KAAK,CAAC;IAClB,CAAC,CAAC;IAEF,IAAIC,IAAI,GAAG,CAAC;IAEZ,WAAW,MAAMpC,GAAG,IAAId,KAAK,EAAE;MAC7B,IAAIc,GAAG,IAAI,IAAI,EAAE;QACf;MACF;MAEAoC,IAAI,IAAIpC,GAAG,CAACC,UAAU;MAEtB,IAAImC,IAAI,KAAK/B,MAAM,EAAE;QACnBnB,KAAK,CAACG,GAAG,CAAC,CAAC;MACb;MAEA,MAAMW,GAAG;IACX;EACF;EAEA,OAAO6B,gBAAgB;AACzB,CAAC;AAED,eAAeN,WAAW"},"metadata":{},"sourceType":"module","externalDependencies":[]}