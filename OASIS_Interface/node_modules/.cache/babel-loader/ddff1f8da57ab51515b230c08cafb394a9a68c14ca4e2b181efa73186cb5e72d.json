{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\nimport \"core-js/modules/es.typed-array.to-reversed.js\";\nimport \"core-js/modules/es.typed-array.to-sorted.js\";\nimport \"core-js/modules/es.typed-array.with.js\";\nimport { logger } from '@libp2p/logger';\nimport { importer } from 'ipfs-unixfs-importer';\nimport { decode } from '@ipld/dag-pb';\nimport { createStat } from './stat.js';\nimport { createMkdir } from './mkdir.js';\nimport { addLink } from './utils/add-link.js';\nimport mergeOpts from 'merge-options';\nimport { createLock } from './utils/create-lock.js';\nimport { toAsyncIterator } from './utils/to-async-iterator.js';\nimport { toMfsPath } from './utils/to-mfs-path.js';\nimport { toPathComponents } from './utils/to-path-components.js';\nimport { toTrail } from './utils/to-trail.js';\nimport { updateTree } from './utils/update-tree.js';\nimport { updateMfsRoot } from './utils/update-mfs-root.js';\nimport errCode from 'err-code';\nimport { MFS_MAX_CHUNK_SIZE } from '../../utils.js';\nimport last from 'it-last';\nimport { withTimeoutOption } from 'ipfs-core-utils/with-timeout-option';\nimport { parseMode, parseMtime } from 'ipfs-unixfs';\nconst mergeOptions = mergeOpts.bind({\n  ignoreUndefined: true\n});\nconst log = logger('ipfs:mfs:write');\n\n/**\n * @typedef {import('multiformats/cid').Version} CIDVersion\n * @typedef {import('ipfs-unixfs').MtimeLike} MtimeLike\n * @typedef {import('./').MfsContext} MfsContext\n * @typedef {import('./utils/to-mfs-path').FilePath} FilePath\n * @typedef {import('./utils/to-mfs-path').MfsPath} MfsPath\n * @typedef {import('multiformats/hashes/interface').MultihashHasher} MultihashHasher\n *\n * @typedef {object} DefaultOptions\n * @property {number} offset\n * @property {number} length\n * @property {boolean} create\n * @property {boolean} truncate\n * @property {boolean} rawLeaves\n * @property {boolean} reduceSingleLeafToSelf\n * @property {CIDVersion} cidVersion\n * @property {string} hashAlg\n * @property {boolean} parents\n * @property {import('ipfs-core-types/src/root').AddProgressFn} progress\n * @property {'trickle' | 'balanced'} strategy\n * @property {boolean} flush\n * @property {'raw' | 'file'} leafType\n * @property {number} shardSplitThreshold\n * @property {MtimeLike} [mtime]\n * @property {number} [mode]\n * @property {AbortSignal} [signal]\n * @property {number} [timeout]\n */\n\n/**\n * @type {DefaultOptions}\n */\nconst defaultOptions = {\n  offset: 0,\n  // the offset in the file to begin writing\n  length: Infinity,\n  // how many bytes from the incoming buffer to write\n  create: false,\n  // whether to create the file if it does not exist\n  truncate: false,\n  // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  parents: false,\n  // whether to create intermediate directories if they do not exist\n  progress: (bytes, path) => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n};\n\n/**\n * @param {MfsContext} context\n */\nexport function createWrite(context) {\n  /**\n   * @type {import('ipfs-core-types/src/files').API<{}>[\"write\"]}\n   */\n  async function mfsWrite(path, content, opts = {}) {\n    /** @type {DefaultOptions} */\n    const options = mergeOptions(defaultOptions, opts);\n\n    /** @type {AsyncIterable<Uint8Array>} */\n    let source;\n    /** @type {MfsPath} */\n    let destination;\n    /** @type {MfsPath} */\n    let parent;\n    log('Reading source, destination and parent');\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content);\n      destination = await toMfsPath(context, path, options);\n      parent = await toMfsPath(context, destination.mfsDirectory, options);\n    })();\n    log('Read source, destination and parent');\n    // @ts-expect-error - parent may be undefined\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n    }\n\n    // @ts-expect-error\n    if (source == null) {\n      throw errCode(new Error('could not create source'), 'ERR_NO_SOURCE');\n    }\n\n    // @ts-expect-error\n    if (destination == null) {\n      throw errCode(new Error('could not create destination'), 'ERR_NO_DESTINATION');\n    }\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST');\n    }\n    if (destination.entryType !== 'file') {\n      throw errCode(new Error('not a file'), 'ERR_NOT_A_FILE');\n    }\n    return updateOrImport(context, path, source, destination, options);\n  }\n  return withTimeoutOption(mfsWrite);\n}\n\n/**\n * @param {MfsContext} context\n * @param {string} path\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options);\n\n  // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path);\n    const fileName = pathComponents.pop();\n    if (fileName == null) {\n      throw errCode(new Error('source does not exist'), 'ERR_NO_EXIST');\n    }\n    let parentExists = false;\n    try {\n      await createStat(context)(`/${pathComponents.join('/')}`, options);\n      parentExists = true;\n    } catch ( /** @type {any} */err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err;\n      }\n    }\n    if (!parentExists) {\n      await createMkdir(context)(`/${pathComponents.join('/')}`, options);\n    }\n\n    // get an updated mfs path in case the root changed while we were writing\n    const updatedPath = await toMfsPath(context, path, options);\n    const trail = await toTrail(context, updatedPath.mfsDirectory);\n    const parent = trail[trail.length - 1];\n    if (!parent) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n    }\n    if (!parent.type || !parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY');\n    }\n    const parentBlock = await context.repo.blocks.get(parent.cid);\n    const parentNode = decode(parentBlock);\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    });\n    parent.cid = result.cid;\n\n    // update the tree with the new child\n    const newRootCid = await updateTree(context, trail, options);\n\n    // Update the MFS record with the new CID for the root of the tree\n    await updateMfsRoot(context, newRootCid, options);\n  })();\n};\n\n/**\n * @param {MfsContext} context\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`);\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`);\n  }\n\n  /** @type {Array<() => AsyncIterable<Uint8Array>>} */\n  const sources = [];\n\n  // pad start of file if necessary\n  if (options.offset > 0) {\n    if (destination.unixfs) {\n      log(`Writing first ${options.offset} bytes of original file`);\n      sources.push(() => {\n        return destination.content({\n          offset: 0,\n          length: options.offset\n        });\n      });\n      if (destination.unixfs.fileSize() < options.offset) {\n        const extra = options.offset - destination.unixfs.fileSize();\n        log(`Writing zeros for extra ${extra} bytes`);\n        sources.push(asyncZeroes(extra));\n      }\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`);\n      sources.push(asyncZeroes(options.offset));\n    }\n  }\n  sources.push(limitAsyncStreamBytes(source, options.length));\n  const content = countBytesStreamed(catAsyncIterators(sources), bytesWritten => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize();\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`);\n        return destination.content({\n          offset: bytesWritten\n        });\n      } else {\n        log('Not writing last bytes from original file');\n      }\n    }\n    return {\n      [Symbol.asyncIterator]: async function* () {}\n    };\n  });\n\n  /** @type {number | undefined} */\n  let mode;\n  if (options.mode !== undefined && options.mode !== null) {\n    mode = parseMode(options.mode);\n  } else if (destination && destination.unixfs) {\n    mode = destination.unixfs.mode;\n  }\n\n  /** @type {import('ipfs-unixfs').Mtime | undefined} */\n  let mtime;\n  if (options.mtime != null) {\n    mtime = parseMtime(options.mtime);\n  } else if (destination && destination.unixfs) {\n    mtime = destination.unixfs.mtime;\n  }\n  const hasher = await context.hashers.getHasher(options.hashAlg);\n  const result = await last(importer([{\n    content: content,\n    // persist mode & mtime if set previously\n    mode,\n    mtime\n  }], context.repo.blocks, {\n    progress: options.progress,\n    hasher,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType\n  }));\n  if (!result) {\n    throw errCode(new Error(`cannot write to ${parent.name}`), 'ERR_COULD_NOT_WRITE');\n  }\n  log(`Wrote ${result.cid}`);\n  return {\n    cid: result.cid,\n    size: result.size\n  };\n};\n\n/**\n * @param {AsyncIterable<Uint8Array>} stream\n * @param {number} limit\n */\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function* _limitAsyncStreamBytes() {\n    let emitted = 0;\n    for await (const buf of stream) {\n      emitted += buf.length;\n      if (emitted > limit) {\n        yield buf.subarray(0, limit - emitted);\n        return;\n      }\n      yield buf;\n    }\n  };\n};\n\n/**\n * @param {number} count\n * @param {number} chunkSize\n */\nconst asyncZeroes = (count, chunkSize = MFS_MAX_CHUNK_SIZE) => {\n  const buf = new Uint8Array(chunkSize);\n  async function* _asyncZeroes() {\n    while (true) {\n      yield buf;\n    }\n  }\n  return limitAsyncStreamBytes(_asyncZeroes(), count);\n};\n\n/**\n * @param {Array<() => AsyncIterable<Uint8Array>>} sources\n */\nconst catAsyncIterators = async function* (sources) {\n  // eslint-disable-line require-await\n  for (let i = 0; i < sources.length; i++) {\n    yield* sources[i]();\n  }\n};\n\n/**\n * @param {AsyncIterable<Uint8Array>} source\n * @param {(count: number) => AsyncIterable<Uint8Array>} notify\n */\nconst countBytesStreamed = async function* (source, notify) {\n  let wrote = 0;\n  for await (const buf of source) {\n    wrote += buf.length;\n    yield buf;\n  }\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length;\n    yield buf;\n  }\n};","map":{"version":3,"names":["logger","importer","decode","createStat","createMkdir","addLink","mergeOpts","createLock","toAsyncIterator","toMfsPath","toPathComponents","toTrail","updateTree","updateMfsRoot","errCode","MFS_MAX_CHUNK_SIZE","last","withTimeoutOption","parseMode","parseMtime","mergeOptions","bind","ignoreUndefined","log","defaultOptions","offset","length","Infinity","create","truncate","rawLeaves","reduceSingleLeafToSelf","cidVersion","hashAlg","parents","progress","bytes","path","strategy","flush","leafType","shardSplitThreshold","createWrite","context","mfsWrite","content","opts","options","source","destination","parent","readLock","mfsDirectory","exists","Error","entryType","updateOrImport","child","write","writeLock","pathComponents","fileName","pop","parentExists","join","err","code","updatedPath","trail","type","includes","name","parentBlock","repo","blocks","get","cid","parentNode","result","size","newRootCid","sources","unixfs","push","fileSize","extra","asyncZeroes","limitAsyncStreamBytes","countBytesStreamed","catAsyncIterators","bytesWritten","Symbol","asyncIterator","mode","undefined","mtime","hasher","hashers","getHasher","stream","limit","_limitAsyncStreamBytes","emitted","buf","subarray","count","chunkSize","Uint8Array","_asyncZeroes","i","notify","wrote"],"sources":["/Users/yezery/Oasis/OASIS/node_modules/.store/ipfs-core@0.18.1/node_modules/ipfs-core/src/components/files/write.js"],"sourcesContent":["import { logger } from '@libp2p/logger'\nimport { importer } from 'ipfs-unixfs-importer'\nimport {\n  decode\n} from '@ipld/dag-pb'\nimport { createStat } from './stat.js'\nimport { createMkdir } from './mkdir.js'\nimport { addLink } from './utils/add-link.js'\nimport mergeOpts from 'merge-options'\nimport { createLock } from './utils/create-lock.js'\nimport { toAsyncIterator } from './utils/to-async-iterator.js'\nimport { toMfsPath } from './utils/to-mfs-path.js'\nimport { toPathComponents } from './utils/to-path-components.js'\nimport { toTrail } from './utils/to-trail.js'\nimport { updateTree } from './utils/update-tree.js'\nimport { updateMfsRoot } from './utils/update-mfs-root.js'\nimport errCode from 'err-code'\nimport {\n  MFS_MAX_CHUNK_SIZE\n} from '../../utils.js'\nimport last from 'it-last'\nimport { withTimeoutOption } from 'ipfs-core-utils/with-timeout-option'\nimport {\n  parseMode,\n  parseMtime\n} from 'ipfs-unixfs'\n\nconst mergeOptions = mergeOpts.bind({ ignoreUndefined: true })\nconst log = logger('ipfs:mfs:write')\n\n/**\n * @typedef {import('multiformats/cid').Version} CIDVersion\n * @typedef {import('ipfs-unixfs').MtimeLike} MtimeLike\n * @typedef {import('./').MfsContext} MfsContext\n * @typedef {import('./utils/to-mfs-path').FilePath} FilePath\n * @typedef {import('./utils/to-mfs-path').MfsPath} MfsPath\n * @typedef {import('multiformats/hashes/interface').MultihashHasher} MultihashHasher\n *\n * @typedef {object} DefaultOptions\n * @property {number} offset\n * @property {number} length\n * @property {boolean} create\n * @property {boolean} truncate\n * @property {boolean} rawLeaves\n * @property {boolean} reduceSingleLeafToSelf\n * @property {CIDVersion} cidVersion\n * @property {string} hashAlg\n * @property {boolean} parents\n * @property {import('ipfs-core-types/src/root').AddProgressFn} progress\n * @property {'trickle' | 'balanced'} strategy\n * @property {boolean} flush\n * @property {'raw' | 'file'} leafType\n * @property {number} shardSplitThreshold\n * @property {MtimeLike} [mtime]\n * @property {number} [mode]\n * @property {AbortSignal} [signal]\n * @property {number} [timeout]\n */\n\n/**\n * @type {DefaultOptions}\n */\nconst defaultOptions = {\n  offset: 0, // the offset in the file to begin writing\n  length: Infinity, // how many bytes from the incoming buffer to write\n  create: false, // whether to create the file if it does not exist\n  truncate: false, // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  parents: false, // whether to create intermediate directories if they do not exist\n  progress: (bytes, path) => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n}\n\n/**\n * @param {MfsContext} context\n */\nexport function createWrite (context) {\n  /**\n   * @type {import('ipfs-core-types/src/files').API<{}>[\"write\"]}\n   */\n  async function mfsWrite (path, content, opts = {}) {\n    /** @type {DefaultOptions} */\n    const options = mergeOptions(defaultOptions, opts)\n\n    /** @type {AsyncIterable<Uint8Array>} */\n    let source\n    /** @type {MfsPath} */\n    let destination\n    /** @type {MfsPath} */\n    let parent\n    log('Reading source, destination and parent')\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content)\n      destination = await toMfsPath(context, path, options)\n      parent = await toMfsPath(context, destination.mfsDirectory, options)\n    })()\n    log('Read source, destination and parent')\n    // @ts-expect-error - parent may be undefined\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST')\n    }\n\n    // @ts-expect-error\n    if (source == null) {\n      throw errCode(new Error('could not create source'), 'ERR_NO_SOURCE')\n    }\n\n    // @ts-expect-error\n    if (destination == null) {\n      throw errCode(new Error('could not create destination'), 'ERR_NO_DESTINATION')\n    }\n\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST')\n    }\n\n    if (destination.entryType !== 'file') {\n      throw errCode(new Error('not a file'), 'ERR_NOT_A_FILE')\n    }\n\n    return updateOrImport(context, path, source, destination, options)\n  }\n\n  return withTimeoutOption(mfsWrite)\n}\n\n/**\n * @param {MfsContext} context\n * @param {string} path\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options)\n\n  // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path)\n    const fileName = pathComponents.pop()\n\n    if (fileName == null) {\n      throw errCode(new Error('source does not exist'), 'ERR_NO_EXIST')\n    }\n\n    let parentExists = false\n\n    try {\n      await createStat(context)(`/${pathComponents.join('/')}`, options)\n      parentExists = true\n    } catch (/** @type {any} */ err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err\n      }\n    }\n\n    if (!parentExists) {\n      await createMkdir(context)(`/${pathComponents.join('/')}`, options)\n    }\n\n    // get an updated mfs path in case the root changed while we were writing\n    const updatedPath = await toMfsPath(context, path, options)\n    const trail = await toTrail(context, updatedPath.mfsDirectory)\n    const parent = trail[trail.length - 1]\n\n    if (!parent) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST')\n    }\n\n    if (!parent.type || !parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY')\n    }\n\n    const parentBlock = await context.repo.blocks.get(parent.cid)\n    const parentNode = decode(parentBlock)\n\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    })\n\n    parent.cid = result.cid\n\n    // update the tree with the new child\n    const newRootCid = await updateTree(context, trail, options)\n\n    // Update the MFS record with the new CID for the root of the tree\n    await updateMfsRoot(context, newRootCid, options)\n  })()\n}\n\n/**\n * @param {MfsContext} context\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`)\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`)\n  }\n\n  /** @type {Array<() => AsyncIterable<Uint8Array>>} */\n  const sources = []\n\n  // pad start of file if necessary\n  if (options.offset > 0) {\n    if (destination.unixfs) {\n      log(`Writing first ${options.offset} bytes of original file`)\n\n      sources.push(\n        () => {\n          return destination.content({\n            offset: 0,\n            length: options.offset\n          })\n        }\n      )\n\n      if (destination.unixfs.fileSize() < options.offset) {\n        const extra = options.offset - destination.unixfs.fileSize()\n\n        log(`Writing zeros for extra ${extra} bytes`)\n        sources.push(\n          asyncZeroes(extra)\n        )\n      }\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`)\n      sources.push(\n        asyncZeroes(options.offset)\n      )\n    }\n  }\n\n  sources.push(\n    limitAsyncStreamBytes(source, options.length)\n  )\n\n  const content = countBytesStreamed(catAsyncIterators(sources), (bytesWritten) => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize()\n\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`)\n\n        return destination.content({\n          offset: bytesWritten\n        })\n      } else {\n        log('Not writing last bytes from original file')\n      }\n    }\n\n    return {\n      [Symbol.asyncIterator]: async function * () {}\n    }\n  })\n\n  /** @type {number | undefined} */\n  let mode\n\n  if (options.mode !== undefined && options.mode !== null) {\n    mode = parseMode(options.mode)\n  } else if (destination && destination.unixfs) {\n    mode = destination.unixfs.mode\n  }\n\n  /** @type {import('ipfs-unixfs').Mtime | undefined} */\n  let mtime\n\n  if (options.mtime != null) {\n    mtime = parseMtime(options.mtime)\n  } else if (destination && destination.unixfs) {\n    mtime = destination.unixfs.mtime\n  }\n\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n\n  const result = await last(importer([{\n    content: content,\n\n    // persist mode & mtime if set previously\n    mode,\n    mtime\n  }], context.repo.blocks, {\n    progress: options.progress,\n    hasher,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType\n  }))\n\n  if (!result) {\n    throw errCode(new Error(`cannot write to ${parent.name}`), 'ERR_COULD_NOT_WRITE')\n  }\n\n  log(`Wrote ${result.cid}`)\n\n  return {\n    cid: result.cid,\n    size: result.size\n  }\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} stream\n * @param {number} limit\n */\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function * _limitAsyncStreamBytes () {\n    let emitted = 0\n\n    for await (const buf of stream) {\n      emitted += buf.length\n\n      if (emitted > limit) {\n        yield buf.subarray(0, limit - emitted)\n\n        return\n      }\n\n      yield buf\n    }\n  }\n}\n\n/**\n * @param {number} count\n * @param {number} chunkSize\n */\nconst asyncZeroes = (count, chunkSize = MFS_MAX_CHUNK_SIZE) => {\n  const buf = new Uint8Array(chunkSize)\n\n  async function * _asyncZeroes () {\n    while (true) {\n      yield buf\n    }\n  }\n\n  return limitAsyncStreamBytes(_asyncZeroes(), count)\n}\n\n/**\n * @param {Array<() => AsyncIterable<Uint8Array>>} sources\n */\nconst catAsyncIterators = async function * (sources) { // eslint-disable-line require-await\n  for (let i = 0; i < sources.length; i++) {\n    yield * sources[i]()\n  }\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} source\n * @param {(count: number) => AsyncIterable<Uint8Array>} notify\n */\nconst countBytesStreamed = async function * (source, notify) {\n  let wrote = 0\n\n  for await (const buf of source) {\n    wrote += buf.length\n\n    yield buf\n  }\n\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length\n\n    yield buf\n  }\n}\n"],"mappings":";;;;AAAA,SAASA,MAAM,QAAQ,gBAAgB;AACvC,SAASC,QAAQ,QAAQ,sBAAsB;AAC/C,SACEC,MAAM,QACD,cAAc;AACrB,SAASC,UAAU,QAAQ,WAAW;AACtC,SAASC,WAAW,QAAQ,YAAY;AACxC,SAASC,OAAO,QAAQ,qBAAqB;AAC7C,OAAOC,SAAS,MAAM,eAAe;AACrC,SAASC,UAAU,QAAQ,wBAAwB;AACnD,SAASC,eAAe,QAAQ,8BAA8B;AAC9D,SAASC,SAAS,QAAQ,wBAAwB;AAClD,SAASC,gBAAgB,QAAQ,+BAA+B;AAChE,SAASC,OAAO,QAAQ,qBAAqB;AAC7C,SAASC,UAAU,QAAQ,wBAAwB;AACnD,SAASC,aAAa,QAAQ,4BAA4B;AAC1D,OAAOC,OAAO,MAAM,UAAU;AAC9B,SACEC,kBAAkB,QACb,gBAAgB;AACvB,OAAOC,IAAI,MAAM,SAAS;AAC1B,SAASC,iBAAiB,QAAQ,qCAAqC;AACvE,SACEC,SAAS,EACTC,UAAU,QACL,aAAa;AAEpB,MAAMC,YAAY,GAAGd,SAAS,CAACe,IAAI,CAAC;EAAEC,eAAe,EAAE;AAAK,CAAC,CAAC;AAC9D,MAAMC,GAAG,GAAGvB,MAAM,CAAC,gBAAgB,CAAC;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAMwB,cAAc,GAAG;EACrBC,MAAM,EAAE,CAAC;EAAE;EACXC,MAAM,EAAEC,QAAQ;EAAE;EAClBC,MAAM,EAAE,KAAK;EAAE;EACfC,QAAQ,EAAE,KAAK;EAAE;EACjBC,SAAS,EAAE,KAAK;EAChBC,sBAAsB,EAAE,KAAK;EAC7BC,UAAU,EAAE,CAAC;EACbC,OAAO,EAAE,UAAU;EACnBC,OAAO,EAAE,KAAK;EAAE;EAChBC,QAAQ,EAAEA,CAACC,KAAK,EAAEC,IAAI,KAAK,CAAC,CAAC;EAC7BC,QAAQ,EAAE,SAAS;EACnBC,KAAK,EAAE,IAAI;EACXC,QAAQ,EAAE,KAAK;EACfC,mBAAmB,EAAE;AACvB,CAAC;;AAED;AACA;AACA;AACA,OAAO,SAASC,WAAWA,CAAEC,OAAO,EAAE;EACpC;AACF;AACA;EACE,eAAeC,QAAQA,CAAEP,IAAI,EAAEQ,OAAO,EAAEC,IAAI,GAAG,CAAC,CAAC,EAAE;IACjD;IACA,MAAMC,OAAO,GAAG3B,YAAY,CAACI,cAAc,EAAEsB,IAAI,CAAC;;IAElD;IACA,IAAIE,MAAM;IACV;IACA,IAAIC,WAAW;IACf;IACA,IAAIC,MAAM;IACV3B,GAAG,CAAC,wCAAwC,CAAC;IAC7C,MAAMhB,UAAU,CAAC,CAAC,CAAC4C,QAAQ,CAAC,YAAY;MACtCH,MAAM,GAAG,MAAMxC,eAAe,CAACqC,OAAO,CAAC;MACvCI,WAAW,GAAG,MAAMxC,SAAS,CAACkC,OAAO,EAAEN,IAAI,EAAEU,OAAO,CAAC;MACrDG,MAAM,GAAG,MAAMzC,SAAS,CAACkC,OAAO,EAAEM,WAAW,CAACG,YAAY,EAAEL,OAAO,CAAC;IACtE,CAAC,CAAC,CAAC,CAAC;IACJxB,GAAG,CAAC,qCAAqC,CAAC;IAC1C;IACA,IAAI,CAACwB,OAAO,CAACb,OAAO,IAAI,CAACgB,MAAM,CAACG,MAAM,EAAE;MACtC,MAAMvC,OAAO,CAAC,IAAIwC,KAAK,CAAC,0BAA0B,CAAC,EAAE,cAAc,CAAC;IACtE;;IAEA;IACA,IAAIN,MAAM,IAAI,IAAI,EAAE;MAClB,MAAMlC,OAAO,CAAC,IAAIwC,KAAK,CAAC,yBAAyB,CAAC,EAAE,eAAe,CAAC;IACtE;;IAEA;IACA,IAAIL,WAAW,IAAI,IAAI,EAAE;MACvB,MAAMnC,OAAO,CAAC,IAAIwC,KAAK,CAAC,8BAA8B,CAAC,EAAE,oBAAoB,CAAC;IAChF;IAEA,IAAI,CAACP,OAAO,CAACnB,MAAM,IAAI,CAACqB,WAAW,CAACI,MAAM,EAAE;MAC1C,MAAMvC,OAAO,CAAC,IAAIwC,KAAK,CAAC,qBAAqB,CAAC,EAAE,cAAc,CAAC;IACjE;IAEA,IAAIL,WAAW,CAACM,SAAS,KAAK,MAAM,EAAE;MACpC,MAAMzC,OAAO,CAAC,IAAIwC,KAAK,CAAC,YAAY,CAAC,EAAE,gBAAgB,CAAC;IAC1D;IAEA,OAAOE,cAAc,CAACb,OAAO,EAAEN,IAAI,EAAEW,MAAM,EAAEC,WAAW,EAAEF,OAAO,CAAC;EACpE;EAEA,OAAO9B,iBAAiB,CAAC2B,QAAQ,CAAC;AACpC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMY,cAAc,GAAG,MAAAA,CAAOb,OAAO,EAAEN,IAAI,EAAEW,MAAM,EAAEC,WAAW,EAAEF,OAAO,KAAK;EAC5E,MAAMU,KAAK,GAAG,MAAMC,KAAK,CAACf,OAAO,EAAEK,MAAM,EAAEC,WAAW,EAAEF,OAAO,CAAC;;EAEhE;EACA;EACA,MAAMxC,UAAU,CAAC,CAAC,CAACoD,SAAS,CAAC,YAAY;IACvC,MAAMC,cAAc,GAAGlD,gBAAgB,CAAC2B,IAAI,CAAC;IAC7C,MAAMwB,QAAQ,GAAGD,cAAc,CAACE,GAAG,CAAC,CAAC;IAErC,IAAID,QAAQ,IAAI,IAAI,EAAE;MACpB,MAAM/C,OAAO,CAAC,IAAIwC,KAAK,CAAC,uBAAuB,CAAC,EAAE,cAAc,CAAC;IACnE;IAEA,IAAIS,YAAY,GAAG,KAAK;IAExB,IAAI;MACF,MAAM5D,UAAU,CAACwC,OAAO,CAAC,CAAE,IAAGiB,cAAc,CAACI,IAAI,CAAC,GAAG,CAAE,EAAC,EAAEjB,OAAO,CAAC;MAClEgB,YAAY,GAAG,IAAI;IACrB,CAAC,CAAC,QAAO,kBAAmBE,GAAG,EAAE;MAC/B,IAAIA,GAAG,CAACC,IAAI,KAAK,eAAe,EAAE;QAChC,MAAMD,GAAG;MACX;IACF;IAEA,IAAI,CAACF,YAAY,EAAE;MACjB,MAAM3D,WAAW,CAACuC,OAAO,CAAC,CAAE,IAAGiB,cAAc,CAACI,IAAI,CAAC,GAAG,CAAE,EAAC,EAAEjB,OAAO,CAAC;IACrE;;IAEA;IACA,MAAMoB,WAAW,GAAG,MAAM1D,SAAS,CAACkC,OAAO,EAAEN,IAAI,EAAEU,OAAO,CAAC;IAC3D,MAAMqB,KAAK,GAAG,MAAMzD,OAAO,CAACgC,OAAO,EAAEwB,WAAW,CAACf,YAAY,CAAC;IAC9D,MAAMF,MAAM,GAAGkB,KAAK,CAACA,KAAK,CAAC1C,MAAM,GAAG,CAAC,CAAC;IAEtC,IAAI,CAACwB,MAAM,EAAE;MACX,MAAMpC,OAAO,CAAC,IAAIwC,KAAK,CAAC,0BAA0B,CAAC,EAAE,cAAc,CAAC;IACtE;IAEA,IAAI,CAACJ,MAAM,CAACmB,IAAI,IAAI,CAACnB,MAAM,CAACmB,IAAI,CAACC,QAAQ,CAAC,WAAW,CAAC,EAAE;MACtD,MAAMxD,OAAO,CAAC,IAAIwC,KAAK,CAAE,mBAAkBJ,MAAM,CAACqB,IAAK,mBAAkB,CAAC,EAAE,qBAAqB,CAAC;IACpG;IAEA,MAAMC,WAAW,GAAG,MAAM7B,OAAO,CAAC8B,IAAI,CAACC,MAAM,CAACC,GAAG,CAACzB,MAAM,CAAC0B,GAAG,CAAC;IAC7D,MAAMC,UAAU,GAAG3E,MAAM,CAACsE,WAAW,CAAC;IAEtC,MAAMM,MAAM,GAAG,MAAMzE,OAAO,CAACsC,OAAO,EAAE;MACpCO,MAAM,EAAE2B,UAAU;MAClBN,IAAI,EAAEV,QAAQ;MACde,GAAG,EAAEnB,KAAK,CAACmB,GAAG;MACdG,IAAI,EAAEtB,KAAK,CAACsB,IAAI;MAChBxC,KAAK,EAAEQ,OAAO,CAACR,KAAK;MACpBE,mBAAmB,EAAEM,OAAO,CAACN,mBAAmB;MAChDR,OAAO,EAAEc,OAAO,CAACd,OAAO;MACxBD,UAAU,EAAEe,OAAO,CAACf;IACtB,CAAC,CAAC;IAEFkB,MAAM,CAAC0B,GAAG,GAAGE,MAAM,CAACF,GAAG;;IAEvB;IACA,MAAMI,UAAU,GAAG,MAAMpE,UAAU,CAAC+B,OAAO,EAAEyB,KAAK,EAAErB,OAAO,CAAC;;IAE5D;IACA,MAAMlC,aAAa,CAAC8B,OAAO,EAAEqC,UAAU,EAAEjC,OAAO,CAAC;EACnD,CAAC,CAAC,CAAC,CAAC;AACN,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,MAAMW,KAAK,GAAG,MAAAA,CAAOf,OAAO,EAAEK,MAAM,EAAEC,WAAW,EAAEF,OAAO,KAAK;EAC7D,IAAIE,WAAW,CAACI,MAAM,EAAE;IACtB9B,GAAG,CAAE,oBAAmB0B,WAAW,CAAC2B,GAAI,WAAU7B,OAAO,CAACtB,MAAO,WAAUsB,OAAO,CAACrB,MAAO,EAAC,CAAC;EAC9F,CAAC,MAAM;IACLH,GAAG,CAAE,uBAAsBwB,OAAO,CAACtB,MAAO,WAAUsB,OAAO,CAACrB,MAAO,EAAC,CAAC;EACvE;;EAEA;EACA,MAAMuD,OAAO,GAAG,EAAE;;EAElB;EACA,IAAIlC,OAAO,CAACtB,MAAM,GAAG,CAAC,EAAE;IACtB,IAAIwB,WAAW,CAACiC,MAAM,EAAE;MACtB3D,GAAG,CAAE,iBAAgBwB,OAAO,CAACtB,MAAO,yBAAwB,CAAC;MAE7DwD,OAAO,CAACE,IAAI,CACV,MAAM;QACJ,OAAOlC,WAAW,CAACJ,OAAO,CAAC;UACzBpB,MAAM,EAAE,CAAC;UACTC,MAAM,EAAEqB,OAAO,CAACtB;QAClB,CAAC,CAAC;MACJ,CACF,CAAC;MAED,IAAIwB,WAAW,CAACiC,MAAM,CAACE,QAAQ,CAAC,CAAC,GAAGrC,OAAO,CAACtB,MAAM,EAAE;QAClD,MAAM4D,KAAK,GAAGtC,OAAO,CAACtB,MAAM,GAAGwB,WAAW,CAACiC,MAAM,CAACE,QAAQ,CAAC,CAAC;QAE5D7D,GAAG,CAAE,2BAA0B8D,KAAM,QAAO,CAAC;QAC7CJ,OAAO,CAACE,IAAI,CACVG,WAAW,CAACD,KAAK,CACnB,CAAC;MACH;IACF,CAAC,MAAM;MACL9D,GAAG,CAAE,2BAA0BwB,OAAO,CAACtB,MAAO,QAAO,CAAC;MACtDwD,OAAO,CAACE,IAAI,CACVG,WAAW,CAACvC,OAAO,CAACtB,MAAM,CAC5B,CAAC;IACH;EACF;EAEAwD,OAAO,CAACE,IAAI,CACVI,qBAAqB,CAACvC,MAAM,EAAED,OAAO,CAACrB,MAAM,CAC9C,CAAC;EAED,MAAMmB,OAAO,GAAG2C,kBAAkB,CAACC,iBAAiB,CAACR,OAAO,CAAC,EAAGS,YAAY,IAAK;IAC/E,IAAIzC,WAAW,CAACiC,MAAM,IAAI,CAACnC,OAAO,CAAClB,QAAQ,EAAE;MAC3C;MACA;MACA,MAAMuD,QAAQ,GAAGnC,WAAW,CAACiC,MAAM,CAACE,QAAQ,CAAC,CAAC;MAE9C,IAAIA,QAAQ,GAAGM,YAAY,EAAE;QAC3BnE,GAAG,CAAE,gBAAe6D,QAAQ,GAAGM,YAAa,OAAMN,QAAS,gDAA+CM,YAAa,EAAC,CAAC;QAEzH,OAAOzC,WAAW,CAACJ,OAAO,CAAC;UACzBpB,MAAM,EAAEiE;QACV,CAAC,CAAC;MACJ,CAAC,MAAM;QACLnE,GAAG,CAAC,2CAA2C,CAAC;MAClD;IACF;IAEA,OAAO;MACL,CAACoE,MAAM,CAACC,aAAa,GAAG,mBAAoB,CAAC;IAC/C,CAAC;EACH,CAAC,CAAC;;EAEF;EACA,IAAIC,IAAI;EAER,IAAI9C,OAAO,CAAC8C,IAAI,KAAKC,SAAS,IAAI/C,OAAO,CAAC8C,IAAI,KAAK,IAAI,EAAE;IACvDA,IAAI,GAAG3E,SAAS,CAAC6B,OAAO,CAAC8C,IAAI,CAAC;EAChC,CAAC,MAAM,IAAI5C,WAAW,IAAIA,WAAW,CAACiC,MAAM,EAAE;IAC5CW,IAAI,GAAG5C,WAAW,CAACiC,MAAM,CAACW,IAAI;EAChC;;EAEA;EACA,IAAIE,KAAK;EAET,IAAIhD,OAAO,CAACgD,KAAK,IAAI,IAAI,EAAE;IACzBA,KAAK,GAAG5E,UAAU,CAAC4B,OAAO,CAACgD,KAAK,CAAC;EACnC,CAAC,MAAM,IAAI9C,WAAW,IAAIA,WAAW,CAACiC,MAAM,EAAE;IAC5Ca,KAAK,GAAG9C,WAAW,CAACiC,MAAM,CAACa,KAAK;EAClC;EAEA,MAAMC,MAAM,GAAG,MAAMrD,OAAO,CAACsD,OAAO,CAACC,SAAS,CAACnD,OAAO,CAACd,OAAO,CAAC;EAE/D,MAAM6C,MAAM,GAAG,MAAM9D,IAAI,CAACf,QAAQ,CAAC,CAAC;IAClC4C,OAAO,EAAEA,OAAO;IAEhB;IACAgD,IAAI;IACJE;EACF,CAAC,CAAC,EAAEpD,OAAO,CAAC8B,IAAI,CAACC,MAAM,EAAE;IACvBvC,QAAQ,EAAEY,OAAO,CAACZ,QAAQ;IAC1B6D,MAAM;IACNhE,UAAU,EAAEe,OAAO,CAACf,UAAU;IAC9BM,QAAQ,EAAES,OAAO,CAACT,QAAQ;IAC1BR,SAAS,EAAEiB,OAAO,CAACjB,SAAS;IAC5BC,sBAAsB,EAAEgB,OAAO,CAAChB,sBAAsB;IACtDS,QAAQ,EAAEO,OAAO,CAACP;EACpB,CAAC,CAAC,CAAC;EAEH,IAAI,CAACsC,MAAM,EAAE;IACX,MAAMhE,OAAO,CAAC,IAAIwC,KAAK,CAAE,mBAAkBJ,MAAM,CAACqB,IAAK,EAAC,CAAC,EAAE,qBAAqB,CAAC;EACnF;EAEAhD,GAAG,CAAE,SAAQuD,MAAM,CAACF,GAAI,EAAC,CAAC;EAE1B,OAAO;IACLA,GAAG,EAAEE,MAAM,CAACF,GAAG;IACfG,IAAI,EAAED,MAAM,CAACC;EACf,CAAC;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA,MAAMQ,qBAAqB,GAAGA,CAACY,MAAM,EAAEC,KAAK,KAAK;EAC/C,OAAO,gBAAiBC,sBAAsBA,CAAA,EAAI;IAChD,IAAIC,OAAO,GAAG,CAAC;IAEf,WAAW,MAAMC,GAAG,IAAIJ,MAAM,EAAE;MAC9BG,OAAO,IAAIC,GAAG,CAAC7E,MAAM;MAErB,IAAI4E,OAAO,GAAGF,KAAK,EAAE;QACnB,MAAMG,GAAG,CAACC,QAAQ,CAAC,CAAC,EAAEJ,KAAK,GAAGE,OAAO,CAAC;QAEtC;MACF;MAEA,MAAMC,GAAG;IACX;EACF,CAAC;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA,MAAMjB,WAAW,GAAGA,CAACmB,KAAK,EAAEC,SAAS,GAAG3F,kBAAkB,KAAK;EAC7D,MAAMwF,GAAG,GAAG,IAAII,UAAU,CAACD,SAAS,CAAC;EAErC,gBAAiBE,YAAYA,CAAA,EAAI;IAC/B,OAAO,IAAI,EAAE;MACX,MAAML,GAAG;IACX;EACF;EAEA,OAAOhB,qBAAqB,CAACqB,YAAY,CAAC,CAAC,EAAEH,KAAK,CAAC;AACrD,CAAC;;AAED;AACA;AACA;AACA,MAAMhB,iBAAiB,GAAG,gBAAAA,CAAkBR,OAAO,EAAE;EAAE;EACrD,KAAK,IAAI4B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG5B,OAAO,CAACvD,MAAM,EAAEmF,CAAC,EAAE,EAAE;IACvC,OAAQ5B,OAAO,CAAC4B,CAAC,CAAC,CAAC,CAAC;EACtB;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA,MAAMrB,kBAAkB,GAAG,gBAAAA,CAAkBxC,MAAM,EAAE8D,MAAM,EAAE;EAC3D,IAAIC,KAAK,GAAG,CAAC;EAEb,WAAW,MAAMR,GAAG,IAAIvD,MAAM,EAAE;IAC9B+D,KAAK,IAAIR,GAAG,CAAC7E,MAAM;IAEnB,MAAM6E,GAAG;EACX;EAEA,WAAW,MAAMA,GAAG,IAAIO,MAAM,CAACC,KAAK,CAAC,EAAE;IACrCA,KAAK,IAAIR,GAAG,CAAC7E,MAAM;IAEnB,MAAM6E,GAAG;EACX;AACF,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}