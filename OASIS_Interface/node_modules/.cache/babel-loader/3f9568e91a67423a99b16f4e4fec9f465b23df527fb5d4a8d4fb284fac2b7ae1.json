{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\nimport * as dagPB from '@ipld/dag-pb';\nimport { CID } from 'multiformats/cid';\nimport { logger } from '@libp2p/logger';\nimport { UnixFS } from 'ipfs-unixfs';\nimport { DirSharded } from './dir-sharded.js';\nimport { updateHamtDirectory, recreateHamtLevel, recreateInitialHamtLevel, createShard, toPrefix, addLinksToHamtBucket } from './hamt-utils.js';\nimport errCode from 'err-code';\nimport last from 'it-last';\nconst log = logger('ipfs:mfs:core:utils:add-link');\n\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').Version} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\nexport async function addLink(context, options) {\n  let parent = options.parent;\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid);\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n    }\n    if (parentCid.code !== dagPB.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID');\n    }\n    log(`Loading parent node ${parentCid}`);\n    const block = await context.repo.blocks.get(parentCid);\n    parent = dagPB.decode(block);\n  }\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n  }\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n  }\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n  }\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n  }\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT');\n  }\n  const meta = UnixFS.unmarshal(parent.Data);\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory');\n    return addToShardedDirectory(context, {\n      ...options,\n      parent\n    });\n  }\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory');\n    return convertToShardedDirectory(context, {\n      ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    });\n  }\n  log(`Adding ${options.name} (${options.cid}) to regular directory`);\n  return addToDirectory(context, {\n    ...options,\n    parent\n  });\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: link.Name || '',\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options);\n  log(`Converted directory to sharded directory ${result.cid}`);\n  return result;\n};\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter(link => {\n    return link.Name !== options.name;\n  });\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  });\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT');\n  }\n  const node = UnixFS.unmarshal(options.parent.Data);\n  let data;\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now();\n    const secs = Math.floor(ms / 1000);\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - secs * 1000) * 1000\n    };\n    data = node.marshal();\n  } else {\n    data = options.parent.Data;\n  }\n  options.parent = dagPB.prepare({\n    Data: data,\n    Links: parentLinks\n  });\n\n  // Persist the new parent PbNode\n  const hasher = await context.hashers.getHasher(options.hashAlg);\n  const buf = dagPB.encode(options.parent);\n  const hash = await hasher.digest(buf);\n  const cid = CID.create(options.cidVersion, dagPB.code, hash);\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf);\n  }\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  };\n};\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard,\n    path\n  } = await addFileToShardedDirectory(context, options);\n  const result = await last(shard.flush(context.repo.blocks));\n  if (!result) {\n    throw new Error('No result from flushing shard');\n  }\n  const block = await context.repo.blocks.get(result.cid);\n  const node = dagPB.decode(block);\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const parentLinks = options.parent.Links.filter(link => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix;\n  });\n  const newLink = node.Links.find(link => (link.Name || '').substring(0, 2) === path[0].prefix);\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`);\n  }\n  parentLinks.push(newLink);\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options);\n};\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  };\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT');\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links);\n  const node = UnixFS.unmarshal(options.parent.Data);\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options);\n  shard._bucket = rootBucket;\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    };\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name);\n  const path = toBucketPath(position);\n  path[0].node = options.parent;\n  let index = 0;\n  while (index < path.length) {\n    const segment = path[index];\n    index++;\n    const node = segment.node;\n    if (!node) {\n      throw new Error('Segment had no node');\n    }\n    const link = node.Links.find(link => (link.Name || '').substring(0, 2) === segment.prefix);\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`);\n      index = path.length;\n      break;\n    }\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`);\n      index = path.length;\n      break;\n    }\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`);\n      index = path.length;\n      break;\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`);\n    const block = await context.repo.blocks.get(link.Hash);\n    const subShard = dagPB.decode(block);\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`);\n      await recreateHamtLevel(context, subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n      const position = await rootBucket._findNewBucketAndPos(file.name);\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      });\n      break;\n    }\n    const nextSegment = path[index];\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(context, subShard.Links, nextSegment.bucket, rootBucket);\n    nextSegment.node = subShard;\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  });\n  return {\n    shard,\n    path\n  };\n};\n\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\nconst toBucketPath = position => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }];\n  let bucket = position.bucket._parent;\n  let positionInBucket = position.bucket._posAtParent;\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n  path.reverse();\n  return path;\n};","map":{"version":3,"names":["dagPB","CID","logger","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","recreateInitialHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","last","log","addLink","context","options","parent","parentCid","asCID","Error","code","block","repo","blocks","get","decode","cid","name","size","Data","meta","unmarshal","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","mtime","mode","addToDirectory","result","map","link","Name","Tsize","Hash","concat","parentLinks","filter","push","node","data","ms","Date","now","secs","Math","floor","nsecs","marshal","prepare","hasher","hashers","getHasher","hashAlg","buf","encode","hash","digest","create","cidVersion","flush","put","shard","path","addFileToShardedDirectory","substring","prefix","newLink","find","bucket","file","rootBucket","root","dir","undefined","parentKey","dirty","flat","_bucket","round","position","_findNewBucketAndPos","toBucketPath","index","segment","subShard","parseInt","pos","nextSegment","_parent","positionInBucket","_posAtParent","reverse"],"sources":["/Users/yezery/Oasis/OASIS/node_modules/.store/ipfs-core@0.18.1/node_modules/ipfs-core/src/components/files/utils/add-link.js"],"sourcesContent":["import * as dagPB from '@ipld/dag-pb'\nimport { CID } from 'multiformats/cid'\nimport { logger } from '@libp2p/logger'\nimport { UnixFS } from 'ipfs-unixfs'\nimport { DirSharded } from './dir-sharded.js'\nimport {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} from './hamt-utils.js'\nimport errCode from 'err-code'\nimport last from 'it-last'\n\nconst log = logger('ipfs:mfs:core:utils:add-link')\n\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').Version} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\nexport async function addLink (context, options) {\n  let parent = options.parent\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid)\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n    }\n\n    if (parentCid.code !== dagPB.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID')\n    }\n\n    log(`Loading parent node ${parentCid}`)\n    const block = await context.repo.blocks.get(parentCid)\n    parent = dagPB.decode(block)\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT')\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, {\n      ...options,\n      parent\n    })\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, {\n      ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    })\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, {\n    ...options,\n    parent\n  })\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: (link.Name || ''),\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter((link) => {\n    return link.Name !== options.name\n  })\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  })\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  let data\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now()\n    const secs = Math.floor(ms / 1000)\n\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n\n    data = node.marshal()\n  } else {\n    data = options.parent.Data\n  }\n  options.parent = dagPB.prepare({\n    Data: data,\n    Links: parentLinks\n  })\n\n  // Persist the new parent PbNode\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n  const buf = dagPB.encode(options.parent)\n  const hash = await hasher.digest(buf)\n  const cid = CID.create(options.cidVersion, dagPB.code, hash)\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf)\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  }\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n  const result = await last(shard.flush(context.repo.blocks))\n\n  if (!result) {\n    throw new Error('No result from flushing shard')\n  }\n\n  const block = await context.repo.blocks.get(result.cid)\n  const node = dagPB.decode(block)\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const parentLinks = options.parent.Links.filter((link) => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix\n  })\n\n  const newLink = node.Links\n    .find(link => (link.Name || '').substring(0, 2) === path[0].prefix)\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`)\n  }\n\n  parentLinks.push(newLink)\n\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options)\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links)\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options)\n  shard._bucket = rootBucket\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    }\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    const segment = path[index]\n    index++\n    const node = segment.node\n\n    if (!node) {\n      throw new Error('Segment had no node')\n    }\n\n    const link = node.Links\n      .find(link => (link.Name || '').substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const block = await context.repo.blocks.get(link.Hash)\n    const subShard = dagPB.decode(block)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(context, subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(context, subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\nconst toBucketPath = (position) => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }]\n\n  let bucket = position.bucket._parent\n  let positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n"],"mappings":";AAAA,OAAO,KAAKA,KAAK,MAAM,cAAc;AACrC,SAASC,GAAG,QAAQ,kBAAkB;AACtC,SAASC,MAAM,QAAQ,gBAAgB;AACvC,SAASC,MAAM,QAAQ,aAAa;AACpC,SAASC,UAAU,QAAQ,kBAAkB;AAC7C,SACEC,mBAAmB,EACnBC,iBAAiB,EACjBC,wBAAwB,EACxBC,WAAW,EACXC,QAAQ,EACRC,oBAAoB,QACf,iBAAiB;AACxB,OAAOC,OAAO,MAAM,UAAU;AAC9B,OAAOC,IAAI,MAAM,SAAS;AAE1B,MAAMC,GAAG,GAAGX,MAAM,CAAC,8BAA8B,CAAC;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAeY,OAAOA,CAAEC,OAAO,EAAEC,OAAO,EAAE;EAC/C,IAAIC,MAAM,GAAGD,OAAO,CAACC,MAAM;EAE3B,IAAID,OAAO,CAACE,SAAS,EAAE;IACrB,MAAMA,SAAS,GAAGjB,GAAG,CAACkB,KAAK,CAACH,OAAO,CAACE,SAAS,CAAC;IAC9C,IAAIA,SAAS,KAAK,IAAI,EAAE;MACtB,MAAMP,OAAO,CAAC,IAAIS,KAAK,CAAC,+BAA+B,CAAC,EAAE,mBAAmB,CAAC;IAChF;IAEA,IAAIF,SAAS,CAACG,IAAI,KAAKrB,KAAK,CAACqB,IAAI,EAAE;MACjC,MAAMV,OAAO,CAAC,IAAIS,KAAK,CAAC,6CAA6C,CAAC,EAAE,mBAAmB,CAAC;IAC9F;IAEAP,GAAG,CAAE,uBAAsBK,SAAU,EAAC,CAAC;IACvC,MAAMI,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAI,CAACC,MAAM,CAACC,GAAG,CAACP,SAAS,CAAC;IACtDD,MAAM,GAAGjB,KAAK,CAAC0B,MAAM,CAACJ,KAAK,CAAC;EAC9B;EAEA,IAAI,CAACL,MAAM,EAAE;IACX,MAAMN,OAAO,CAAC,IAAIS,KAAK,CAAC,yCAAyC,CAAC,EAAE,gBAAgB,CAAC;EACvF;EAEA,IAAI,CAACJ,OAAO,CAACW,GAAG,EAAE;IAChB,MAAMhB,OAAO,CAAC,IAAIS,KAAK,CAAC,gCAAgC,CAAC,EAAE,kBAAkB,CAAC;EAChF;EAEA,IAAI,CAACJ,OAAO,CAACY,IAAI,EAAE;IACjB,MAAMjB,OAAO,CAAC,IAAIS,KAAK,CAAC,iCAAiC,CAAC,EAAE,mBAAmB,CAAC;EAClF;EAEA,IAAI,CAACJ,OAAO,CAACa,IAAI,IAAIb,OAAO,CAACa,IAAI,KAAK,CAAC,EAAE;IACvC,MAAMlB,OAAO,CAAC,IAAIS,KAAK,CAAC,iCAAiC,CAAC,EAAE,mBAAmB,CAAC;EAClF;EAEA,IAAI,CAACH,MAAM,CAACa,IAAI,EAAE;IAChB,MAAMnB,OAAO,CAAC,IAAIS,KAAK,CAAC,4CAA4C,CAAC,EAAE,oBAAoB,CAAC;EAC9F;EAEA,MAAMW,IAAI,GAAG5B,MAAM,CAAC6B,SAAS,CAACf,MAAM,CAACa,IAAI,CAAC;EAE1C,IAAIC,IAAI,CAACE,IAAI,KAAK,wBAAwB,EAAE;IAC1CpB,GAAG,CAAC,kCAAkC,CAAC;IAEvC,OAAOqB,qBAAqB,CAACnB,OAAO,EAAE;MACpC,GAAGC,OAAO;MACVC;IACF,CAAC,CAAC;EACJ;EAEA,IAAIA,MAAM,CAACkB,KAAK,CAACC,MAAM,IAAIpB,OAAO,CAACqB,mBAAmB,EAAE;IACtDxB,GAAG,CAAC,2CAA2C,CAAC;IAEhD,OAAOyB,yBAAyB,CAACvB,OAAO,EAAE;MACxC,GAAGC,OAAO;MACVC,MAAM;MACNsB,KAAK,EAAER,IAAI,CAACQ,KAAK;MACjBC,IAAI,EAAET,IAAI,CAACS;IACb,CAAC,CAAC;EACJ;EAEA3B,GAAG,CAAE,UAASG,OAAO,CAACY,IAAK,KAAIZ,OAAO,CAACW,GAAI,wBAAuB,CAAC;EAEnE,OAAOc,cAAc,CAAC1B,OAAO,EAAE;IAC7B,GAAGC,OAAO;IACVC;EACF,CAAC,CAAC;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMqB,yBAAyB,GAAG,MAAAA,CAAOvB,OAAO,EAAEC,OAAO,KAAK;EAC5D,MAAM0B,MAAM,GAAG,MAAMlC,WAAW,CAACO,OAAO,EAAEC,OAAO,CAACC,MAAM,CAACkB,KAAK,CAACQ,GAAG,CAACC,IAAI,KAAK;IAC1EhB,IAAI,EAAGgB,IAAI,CAACC,IAAI,IAAI,EAAG;IACvBhB,IAAI,EAAEe,IAAI,CAACE,KAAK,IAAI,CAAC;IACrBnB,GAAG,EAAEiB,IAAI,CAACG;EACZ,CAAC,CAAC,CAAC,CAACC,MAAM,CAAC;IACTpB,IAAI,EAAEZ,OAAO,CAACY,IAAI;IAClBC,IAAI,EAAEb,OAAO,CAACa,IAAI;IAClBF,GAAG,EAAEX,OAAO,CAACW;EACf,CAAC,CAAC,EAAEX,OAAO,CAAC;EAEZH,GAAG,CAAE,4CAA2C6B,MAAM,CAACf,GAAI,EAAC,CAAC;EAE7D,OAAOe,MAAM;AACf,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMD,cAAc,GAAG,MAAAA,CAAO1B,OAAO,EAAEC,OAAO,KAAK;EACjD;EACA,MAAMiC,WAAW,GAAGjC,OAAO,CAACC,MAAM,CAACkB,KAAK,CAACe,MAAM,CAAEN,IAAI,IAAK;IACxD,OAAOA,IAAI,CAACC,IAAI,KAAK7B,OAAO,CAACY,IAAI;EACnC,CAAC,CAAC;EACFqB,WAAW,CAACE,IAAI,CAAC;IACfN,IAAI,EAAE7B,OAAO,CAACY,IAAI;IAClBkB,KAAK,EAAE9B,OAAO,CAACa,IAAI;IACnBkB,IAAI,EAAE/B,OAAO,CAACW;EAChB,CAAC,CAAC;EAEF,IAAI,CAACX,OAAO,CAACC,MAAM,CAACa,IAAI,EAAE;IACxB,MAAMnB,OAAO,CAAC,IAAIS,KAAK,CAAC,mDAAmD,CAAC,EAAE,oBAAoB,CAAC;EACrG;EAEA,MAAMgC,IAAI,GAAGjD,MAAM,CAAC6B,SAAS,CAAChB,OAAO,CAACC,MAAM,CAACa,IAAI,CAAC;EAElD,IAAIuB,IAAI;EACR,IAAID,IAAI,CAACb,KAAK,EAAE;IACd;IACA,MAAMe,EAAE,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;IACrB,MAAMC,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACL,EAAE,GAAG,IAAI,CAAC;IAElCF,IAAI,CAACb,KAAK,GAAG;MACXkB,IAAI,EAAEA,IAAI;MACVG,KAAK,EAAE,CAACN,EAAE,GAAIG,IAAI,GAAG,IAAK,IAAI;IAChC,CAAC;IAEDJ,IAAI,GAAGD,IAAI,CAACS,OAAO,CAAC,CAAC;EACvB,CAAC,MAAM;IACLR,IAAI,GAAGrC,OAAO,CAACC,MAAM,CAACa,IAAI;EAC5B;EACAd,OAAO,CAACC,MAAM,GAAGjB,KAAK,CAAC8D,OAAO,CAAC;IAC7BhC,IAAI,EAAEuB,IAAI;IACVlB,KAAK,EAAEc;EACT,CAAC,CAAC;;EAEF;EACA,MAAMc,MAAM,GAAG,MAAMhD,OAAO,CAACiD,OAAO,CAACC,SAAS,CAACjD,OAAO,CAACkD,OAAO,CAAC;EAC/D,MAAMC,GAAG,GAAGnE,KAAK,CAACoE,MAAM,CAACpD,OAAO,CAACC,MAAM,CAAC;EACxC,MAAMoD,IAAI,GAAG,MAAMN,MAAM,CAACO,MAAM,CAACH,GAAG,CAAC;EACrC,MAAMxC,GAAG,GAAG1B,GAAG,CAACsE,MAAM,CAACvD,OAAO,CAACwD,UAAU,EAAExE,KAAK,CAACqB,IAAI,EAAEgD,IAAI,CAAC;EAE5D,IAAIrD,OAAO,CAACyD,KAAK,EAAE;IACjB,MAAM1D,OAAO,CAACQ,IAAI,CAACC,MAAM,CAACkD,GAAG,CAAC/C,GAAG,EAAEwC,GAAG,CAAC;EACzC;EAEA,OAAO;IACLf,IAAI,EAAEpC,OAAO,CAACC,MAAM;IACpBU,GAAG;IACHE,IAAI,EAAEsC,GAAG,CAAC/B;EACZ,CAAC;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMF,qBAAqB,GAAG,MAAAA,CAAOnB,OAAO,EAAEC,OAAO,KAAK;EACxD,MAAM;IACJ2D,KAAK;IAAEC;EACT,CAAC,GAAG,MAAMC,yBAAyB,CAAC9D,OAAO,EAAEC,OAAO,CAAC;EACrD,MAAM0B,MAAM,GAAG,MAAM9B,IAAI,CAAC+D,KAAK,CAACF,KAAK,CAAC1D,OAAO,CAACQ,IAAI,CAACC,MAAM,CAAC,CAAC;EAE3D,IAAI,CAACkB,MAAM,EAAE;IACX,MAAM,IAAItB,KAAK,CAAC,+BAA+B,CAAC;EAClD;EAEA,MAAME,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAI,CAACC,MAAM,CAACC,GAAG,CAACiB,MAAM,CAACf,GAAG,CAAC;EACvD,MAAMyB,IAAI,GAAGpD,KAAK,CAAC0B,MAAM,CAACJ,KAAK,CAAC;;EAEhC;EACA,MAAM2B,WAAW,GAAGjC,OAAO,CAACC,MAAM,CAACkB,KAAK,CAACe,MAAM,CAAEN,IAAI,IAAK;IACxD;IACA;IACA,OAAO,CAACA,IAAI,CAACC,IAAI,IAAI,EAAE,EAAEiC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,KAAKF,IAAI,CAAC,CAAC,CAAC,CAACG,MAAM;EAC7D,CAAC,CAAC;EAEF,MAAMC,OAAO,GAAG5B,IAAI,CAACjB,KAAK,CACvB8C,IAAI,CAACrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAI,IAAI,EAAE,EAAEiC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,KAAKF,IAAI,CAAC,CAAC,CAAC,CAACG,MAAM,CAAC;EAErE,IAAI,CAACC,OAAO,EAAE;IACZ,MAAM,IAAI5D,KAAK,CAAE,6BAA4BwD,IAAI,CAAC,CAAC,CAAC,CAACG,MAAO,EAAC,CAAC;EAChE;EAEA9B,WAAW,CAACE,IAAI,CAAC6B,OAAO,CAAC;EAEzB,OAAO3E,mBAAmB,CAACU,OAAO,EAAEkC,WAAW,EAAE2B,IAAI,CAAC,CAAC,CAAC,CAACM,MAAM,EAAElE,OAAO,CAAC;AAC3E,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM6D,yBAAyB,GAAG,MAAAA,CAAO9D,OAAO,EAAEC,OAAO,KAAK;EAC5D,MAAMmE,IAAI,GAAG;IACXvD,IAAI,EAAEZ,OAAO,CAACY,IAAI;IAClBD,GAAG,EAAEX,OAAO,CAACW,GAAG;IAChBE,IAAI,EAAEb,OAAO,CAACa;EAChB,CAAC;EAED,IAAI,CAACb,OAAO,CAACC,MAAM,CAACa,IAAI,EAAE;IACxB,MAAMnB,OAAO,CAAC,IAAIS,KAAK,CAAC,8DAA8D,CAAC,EAAE,oBAAoB,CAAC;EAChH;;EAEA;EACA,MAAMgE,UAAU,GAAG,MAAM7E,wBAAwB,CAACS,OAAO,CAACC,MAAM,CAACkB,KAAK,CAAC;EACvE,MAAMiB,IAAI,GAAGjD,MAAM,CAAC6B,SAAS,CAAChB,OAAO,CAACC,MAAM,CAACa,IAAI,CAAC;EAElD,MAAM6C,KAAK,GAAG,IAAIvE,UAAU,CAAC;IAC3BiF,IAAI,EAAE,IAAI;IACVC,GAAG,EAAE,IAAI;IACTrE,MAAM,EAAEsE,SAAS;IACjBC,SAAS,EAAED,SAAS;IACpBX,IAAI,EAAE,EAAE;IACRa,KAAK,EAAE,IAAI;IACXC,IAAI,EAAE,KAAK;IACXlD,IAAI,EAAEY,IAAI,CAACZ;EACb,CAAC,EAAExB,OAAO,CAAC;EACX2D,KAAK,CAACgB,OAAO,GAAGP,UAAU;EAE1B,IAAIhC,IAAI,CAACb,KAAK,EAAE;IACd;IACAoC,KAAK,CAACpC,KAAK,GAAG;MACZkB,IAAI,EAAEC,IAAI,CAACkC,KAAK,CAACrC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,IAAI;IACpC,CAAC;EACH;;EAEA;EACA,MAAMqC,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAoB,CAACX,IAAI,CAACvD,IAAI,CAAC;EACjE,MAAMgD,IAAI,GAAGmB,YAAY,CAACF,QAAQ,CAAC;EACnCjB,IAAI,CAAC,CAAC,CAAC,CAACxB,IAAI,GAAGpC,OAAO,CAACC,MAAM;EAC7B,IAAI+E,KAAK,GAAG,CAAC;EAEb,OAAOA,KAAK,GAAGpB,IAAI,CAACxC,MAAM,EAAE;IAC1B,MAAM6D,OAAO,GAAGrB,IAAI,CAACoB,KAAK,CAAC;IAC3BA,KAAK,EAAE;IACP,MAAM5C,IAAI,GAAG6C,OAAO,CAAC7C,IAAI;IAEzB,IAAI,CAACA,IAAI,EAAE;MACT,MAAM,IAAIhC,KAAK,CAAC,qBAAqB,CAAC;IACxC;IAEA,MAAMwB,IAAI,GAAGQ,IAAI,CAACjB,KAAK,CACpB8C,IAAI,CAACrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAI,IAAI,EAAE,EAAEiC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,KAAKmB,OAAO,CAAClB,MAAM,CAAC;IAErE,IAAI,CAACnC,IAAI,EAAE;MACT;MACA/B,GAAG,CAAE,QAAOoF,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,gBAAe,CAAC;MACvDoE,KAAK,GAAGpB,IAAI,CAACxC,MAAM;MAEnB;IACF;IAEA,IAAIQ,IAAI,CAACC,IAAI,KAAM,GAAEoD,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,EAAC,EAAE;MACjD;MACAf,GAAG,CAAE,QAAOoF,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,mBAAkB,CAAC;MAC1DoE,KAAK,GAAGpB,IAAI,CAACxC,MAAM;MAEnB;IACF;IAEA,IAAI,CAACQ,IAAI,CAACC,IAAI,IAAI,EAAE,EAAET,MAAM,GAAG,CAAC,EAAE;MAChC;MACAvB,GAAG,CAAE,QAAO+B,IAAI,CAACC,IAAK,IAAGD,IAAI,CAACG,IAAK,mCAAkC,CAAC;MACtEiD,KAAK,GAAGpB,IAAI,CAACxC,MAAM;MAEnB;IACF;;IAEA;IACAvB,GAAG,CAAE,kBAAiBoF,OAAO,CAAClB,MAAO,EAAC,CAAC;IACvC,MAAMzD,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAI,CAACC,MAAM,CAACC,GAAG,CAACmB,IAAI,CAACG,IAAI,CAAC;IACtD,MAAMmD,QAAQ,GAAGlG,KAAK,CAAC0B,MAAM,CAACJ,KAAK,CAAC;;IAEpC;IACA,IAAI,CAACsD,IAAI,CAACoB,KAAK,CAAC,EAAE;MAChBnF,GAAG,CAAE,uBAAsBoF,OAAO,CAAClB,MAAO,EAAC,CAAC;MAC5C,MAAMzE,iBAAiB,CAACS,OAAO,EAAEmF,QAAQ,CAAC/D,KAAK,EAAEiD,UAAU,EAAEa,OAAO,CAACf,MAAM,EAAEiB,QAAQ,CAACF,OAAO,CAAClB,MAAM,EAAE,EAAE,CAAC,CAAC;MAE1G,MAAMc,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAoB,CAACX,IAAI,CAACvD,IAAI,CAAC;MAEjEgD,IAAI,CAACzB,IAAI,CAAC;QACR+B,MAAM,EAAEW,QAAQ,CAACX,MAAM;QACvBH,MAAM,EAAEtE,QAAQ,CAACoF,QAAQ,CAACO,GAAG,CAAC;QAC9BhD,IAAI,EAAE8C;MACR,CAAC,CAAC;MAEF;IACF;IAEA,MAAMG,WAAW,GAAGzB,IAAI,CAACoB,KAAK,CAAC;;IAE/B;IACA,MAAMtF,oBAAoB,CAACK,OAAO,EAAEmF,QAAQ,CAAC/D,KAAK,EAAEkE,WAAW,CAACnB,MAAM,EAAEE,UAAU,CAAC;IAEnFiB,WAAW,CAACjD,IAAI,GAAG8C,QAAQ;EAC7B;;EAEA;EACA,MAAMvB,KAAK,CAACgB,OAAO,CAACjB,GAAG,CAACS,IAAI,CAACvD,IAAI,EAAE;IACjCC,IAAI,EAAEsD,IAAI,CAACtD,IAAI;IACfF,GAAG,EAAEwD,IAAI,CAACxD;EACZ,CAAC,CAAC;EAEF,OAAO;IACLgD,KAAK;IAAEC;EACT,CAAC;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA,MAAMmB,YAAY,GAAIF,QAAQ,IAAK;EACjC,MAAMjB,IAAI,GAAG,CAAC;IACZM,MAAM,EAAEW,QAAQ,CAACX,MAAM;IACvBH,MAAM,EAAEtE,QAAQ,CAACoF,QAAQ,CAACO,GAAG;EAC/B,CAAC,CAAC;EAEF,IAAIlB,MAAM,GAAGW,QAAQ,CAACX,MAAM,CAACoB,OAAO;EACpC,IAAIC,gBAAgB,GAAGV,QAAQ,CAACX,MAAM,CAACsB,YAAY;EAEnD,OAAOtB,MAAM,EAAE;IACbN,IAAI,CAACzB,IAAI,CAAC;MACR+B,MAAM;MACNH,MAAM,EAAEtE,QAAQ,CAAC8F,gBAAgB;IACnC,CAAC,CAAC;IAEFA,gBAAgB,GAAGrB,MAAM,CAACsB,YAAY;IACtCtB,MAAM,GAAGA,MAAM,CAACoB,OAAO;EACzB;EAEA1B,IAAI,CAAC6B,OAAO,CAAC,CAAC;EAEd,OAAO7B,IAAI;AACb,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}