{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, util } from '@tensorflow/tfjs-core';\nimport { ConcatProgram } from '../concat_gpu';\nimport { ConcatPackedProgram } from '../concat_packed_gpu';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concatImpl(inputs, axis, backend) {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map(t => real({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const imags = inputs.map(t => imag({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n    const result = complex({\n      inputs: {\n        real: realConcated,\n        imag: imagConcated\n      },\n      backend\n    });\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n    return result;\n  }\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({\n        inputs: {\n          x: t\n        },\n        backend,\n        attrs: {\n          shape\n        }\n      });\n    });\n    const inputsValShapes = tensors2D.map(t => {\n      return {\n        vals: backend.readSync(t.dataId),\n        shape: t.shape\n      };\n    });\n    // Concats 2d tensors along axis=1.\n    const outShape = backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n    const finalOutShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n    tensors2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return outInfo;\n  }\n  if (inputs.length > env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n    const midIndex = Math.floor(inputs.length / 2);\n    const leftSide = concatImpl(inputs.slice(0, midIndex), axis, backend);\n    const rightSide = concatImpl(inputs.slice(midIndex), axis, backend);\n    const result = concatImpl([leftSide, rightSide], axis, backend);\n    backend.disposeIntermediateTensorInfo(leftSide);\n    backend.disposeIntermediateTensorInfo(rightSide);\n    return result;\n  }\n  if (env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') && inputs[0].shape.length > 1) {\n    const program = new ConcatPackedProgram(inputs.map(t => t.shape), axis);\n    return backend.runWebGLProgram(program, inputs, dtype);\n  }\n  const {\n    tensors2D,\n    outShape\n  } = computeTensors2D(inputs, axis, backend);\n  const program = new ConcatProgram(tensors2D.map(t => t.shape));\n  const result = backend.runWebGLProgram(program, tensors2D, dtype);\n  tensors2D.forEach(r => backend.disposeIntermediateTensorInfo(r));\n  const reshapedResult = reshape({\n    inputs: {\n      x: result\n    },\n    attrs: {\n      shape: outShape\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(result);\n  return reshapedResult;\n}\nfunction computeTensors2D(inputs, axis, backend) {\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(x => reshape({\n    inputs: {\n      x\n    },\n    attrs: {\n      shape: [-1, util.sizeFromShape(x.shape.slice(axis))]\n    },\n    backend\n  }));\n  return {\n    tensors2D,\n    outShape\n  };\n}","map":{"version":3,"names":["backend_util","env","util","ConcatProgram","ConcatPackedProgram","concatImplCPU","complex","imag","real","reshape","concatImpl","inputs","axis","backend","dtype","reals","map","t","input","imags","realConcated","imagConcated","result","forEach","r","disposeIntermediateTensorInfo","i","runOnCpu","shouldExecuteOnCPU","tensors2D","innerSize","sizeFromShape","shape","slice","x","attrs","inputsValShapes","vals","readSync","dataId","outShape","computeOutShape","simplyConcat","outVals","finalOutShape","outInfo","makeTensorInfo","length","getNumber","midIndex","Math","floor","leftSide","rightSide","getBool","program","runWebGLProgram","computeTensors2D","reshapedResult"],"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Concat_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, ConcatInputs, env, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {ConcatProgram} from '../concat_gpu';\nimport {ConcatPackedProgram} from '../concat_packed_gpu';\nimport {concatImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concatImpl(\n    inputs: ConcatInputs, axis: number, backend: MathBackendWebGL): TensorInfo {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = tensors2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    const outShape =\n        backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals =\n        concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n\n    const finalOutShape =\n        backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n\n    tensors2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n    return outInfo;\n  }\n\n  if (inputs.length > env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n    const midIndex = Math.floor(inputs.length / 2);\n    const leftSide = concatImpl(inputs.slice(0, midIndex), axis, backend);\n    const rightSide = concatImpl(inputs.slice(midIndex), axis, backend);\n\n    const result = concatImpl([leftSide, rightSide], axis, backend);\n\n    backend.disposeIntermediateTensorInfo(leftSide);\n    backend.disposeIntermediateTensorInfo(rightSide);\n\n    return result;\n  }\n\n  if (env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') &&\n      inputs[0].shape.length > 1) {\n    const program = new ConcatPackedProgram(inputs.map(t => t.shape), axis);\n    return backend.runWebGLProgram(program, inputs, dtype);\n  }\n\n  const {tensors2D, outShape} = computeTensors2D(inputs, axis, backend);\n  const program =\n      new ConcatProgram(tensors2D.map(t => t.shape as [number, number]));\n  const result = backend.runWebGLProgram(program, tensors2D, dtype);\n\n  tensors2D.forEach(r => backend.disposeIntermediateTensorInfo(r));\n  const reshapedResult =\n      reshape({inputs: {x: result}, attrs: {shape: outShape}, backend});\n  backend.disposeIntermediateTensorInfo(result);\n\n  return reshapedResult;\n}\n\nfunction computeTensors2D(\n    inputs: ConcatInputs, axis: number, backend: MathBackendWebGL) {\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(\n      x => reshape({\n        inputs: {x},\n        attrs: {shape: [-1, util.sizeFromShape(x.shape.slice(axis))]},\n        backend\n      }));\n\n  return {tensors2D, outShape};\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAAgBC,GAAG,EAAcC,IAAI,QAAO,uBAAuB;AAGvF,SAAQC,aAAa,QAAO,eAAe;AAC3C,SAAQC,mBAAmB,QAAO,sBAAsB;AACxD,SAAQC,aAAa,QAAO,wBAAwB;AAEpD,SAAQC,OAAO,QAAO,WAAW;AACjC,SAAQC,IAAI,QAAO,QAAQ;AAC3B,SAAQC,IAAI,QAAO,QAAQ;AAC3B,SAAQC,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAUC,UAAUA,CACtBC,MAAoB,EAAEC,IAAY,EAAEC,OAAyB;EAC/D,MAAMC,KAAK,GAAGH,MAAM,CAAC,CAAC,CAAC,CAACG,KAAK;EAC7B,IAAIA,KAAK,KAAK,WAAW,EAAE;IACzB,MAAMC,KAAK,GAAGJ,MAAM,CAACK,GAAG,CAAEC,CAAC,IAAKT,IAAI,CAAC;MAACG,MAAM,EAAE;QAACO,KAAK,EAAED;MAAC,CAAC;MAAEJ;IAAO,CAAC,CAAC,CAAC;IACpE,MAAMM,KAAK,GAAGR,MAAM,CAACK,GAAG,CAAEC,CAAC,IAAKV,IAAI,CAAC;MAACI,MAAM,EAAE;QAACO,KAAK,EAAED;MAAC,CAAC;MAAEJ;IAAO,CAAC,CAAC,CAAC;IAEpE,MAAMO,YAAY,GAAGV,UAAU,CAACK,KAAK,EAAEH,IAAI,EAAEC,OAAO,CAAC;IACrD,MAAMQ,YAAY,GAAGX,UAAU,CAACS,KAAK,EAAEP,IAAI,EAAEC,OAAO,CAAC;IAErD,MAAMS,MAAM,GACRhB,OAAO,CAAC;MAACK,MAAM,EAAE;QAACH,IAAI,EAAEY,YAAY;QAAEb,IAAI,EAAEc;MAAY,CAAC;MAAER;IAAO,CAAC,CAAC;IAExEE,KAAK,CAACQ,OAAO,CAACC,CAAC,IAAIX,OAAO,CAACY,6BAA6B,CAACD,CAAC,CAAC,CAAC;IAC5DL,KAAK,CAACI,OAAO,CAACG,CAAC,IAAIb,OAAO,CAACY,6BAA6B,CAACC,CAAC,CAAC,CAAC;IAC5Db,OAAO,CAACY,6BAA6B,CAACL,YAAY,CAAC;IACnDP,OAAO,CAACY,6BAA6B,CAACJ,YAAY,CAAC;IAEnD,OAAOC,MAAM;;EAGf,IAAIK,QAAQ,GAAGd,OAAO,CAACe,kBAAkB,CAACjB,MAAM,CAAC;EAEjD;EACA;EACA;EACA;EACA;EACA;EACA,IAAIG,KAAK,KAAK,QAAQ,EAAE;IACtBa,QAAQ,GAAG,IAAI;;EAGjB,IAAIA,QAAQ,EAAE;IACZ;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAME,SAAS,GAAGlB,MAAM,CAACK,GAAG,CAACC,CAAC,IAAG;MAC/B,MAAMa,SAAS,GAAG5B,IAAI,CAAC6B,aAAa,CAACd,CAAC,CAACe,KAAK,CAACC,KAAK,CAACrB,IAAI,CAAC,CAAC;MACzD,MAAMoB,KAAK,GAAG,CAAC,CAAC,CAAC,EAAEF,SAAS,CAAC;MAC7B,OAAOrB,OAAO,CAAC;QAACE,MAAM,EAAE;UAACuB,CAAC,EAAEjB;QAAC,CAAC;QAAEJ,OAAO;QAAEsB,KAAK,EAAE;UAACH;QAAK;MAAC,CAAC,CAAC;IAC3D,CAAC,CAAC;IAEF,MAAMI,eAAe,GAAGP,SAAS,CAACb,GAAG,CAACC,CAAC,IAAG;MACxC,OAAO;QAACoB,IAAI,EAAExB,OAAO,CAACyB,QAAQ,CAACrB,CAAC,CAACsB,MAAM,CAAC;QAAEP,KAAK,EAAEf,CAAC,CAACe;MAAK,CAAC;IAC3D,CAAC,CAAC;IAEF;IACA,MAAMQ,QAAQ,GACVxC,YAAY,CAACyC,eAAe,CAACZ,SAAS,CAACb,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACe,KAAK,CAAC,EAAE,CAAC,CAAC,UAAU,CAAC;IAC3E,MAAMU,YAAY,GAAGb,SAAS,CAAC,CAAC,CAAC,CAACG,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;IAChD,MAAMW,OAAO,GACTtC,aAAa,CAAC+B,eAAe,EAAEI,QAAQ,EAAE1B,KAAK,EAAE4B,YAAY,CAAC;IAEjE,MAAME,aAAa,GACf5C,YAAY,CAACyC,eAAe,CAAC9B,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACe,KAAK,CAAC,EAAEpB,IAAI,CAAC;IAEhE,MAAMiC,OAAO,GAAGhC,OAAO,CAACiC,cAAc,CAACF,aAAa,EAAE9B,KAAK,EAAE6B,OAAO,CAAC;IAErEd,SAAS,CAACN,OAAO,CAACN,CAAC,IAAIJ,OAAO,CAACY,6BAA6B,CAACR,CAAC,CAAC,CAAC;IAEhE,OAAO4B,OAAO;;EAGhB,IAAIlC,MAAM,CAACoC,MAAM,GAAG9C,GAAG,EAAE,CAAC+C,SAAS,CAAC,8BAA8B,CAAC,EAAE;IACnE,MAAMC,QAAQ,GAAGC,IAAI,CAACC,KAAK,CAACxC,MAAM,CAACoC,MAAM,GAAG,CAAC,CAAC;IAC9C,MAAMK,QAAQ,GAAG1C,UAAU,CAACC,MAAM,CAACsB,KAAK,CAAC,CAAC,EAAEgB,QAAQ,CAAC,EAAErC,IAAI,EAAEC,OAAO,CAAC;IACrE,MAAMwC,SAAS,GAAG3C,UAAU,CAACC,MAAM,CAACsB,KAAK,CAACgB,QAAQ,CAAC,EAAErC,IAAI,EAAEC,OAAO,CAAC;IAEnE,MAAMS,MAAM,GAAGZ,UAAU,CAAC,CAAC0C,QAAQ,EAAEC,SAAS,CAAC,EAAEzC,IAAI,EAAEC,OAAO,CAAC;IAE/DA,OAAO,CAACY,6BAA6B,CAAC2B,QAAQ,CAAC;IAC/CvC,OAAO,CAACY,6BAA6B,CAAC4B,SAAS,CAAC;IAEhD,OAAO/B,MAAM;;EAGf,IAAIrB,GAAG,EAAE,CAACqD,OAAO,CAAC,6BAA6B,CAAC,IAC5C3C,MAAM,CAAC,CAAC,CAAC,CAACqB,KAAK,CAACe,MAAM,GAAG,CAAC,EAAE;IAC9B,MAAMQ,OAAO,GAAG,IAAInD,mBAAmB,CAACO,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACe,KAAK,CAAC,EAAEpB,IAAI,CAAC;IACvE,OAAOC,OAAO,CAAC2C,eAAe,CAACD,OAAO,EAAE5C,MAAM,EAAEG,KAAK,CAAC;;EAGxD,MAAM;IAACe,SAAS;IAAEW;EAAQ,CAAC,GAAGiB,gBAAgB,CAAC9C,MAAM,EAAEC,IAAI,EAAEC,OAAO,CAAC;EACrE,MAAM0C,OAAO,GACT,IAAIpD,aAAa,CAAC0B,SAAS,CAACb,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACe,KAAyB,CAAC,CAAC;EACtE,MAAMV,MAAM,GAAGT,OAAO,CAAC2C,eAAe,CAACD,OAAO,EAAE1B,SAAS,EAAEf,KAAK,CAAC;EAEjEe,SAAS,CAACN,OAAO,CAACC,CAAC,IAAIX,OAAO,CAACY,6BAA6B,CAACD,CAAC,CAAC,CAAC;EAChE,MAAMkC,cAAc,GAChBjD,OAAO,CAAC;IAACE,MAAM,EAAE;MAACuB,CAAC,EAAEZ;IAAM,CAAC;IAAEa,KAAK,EAAE;MAACH,KAAK,EAAEQ;IAAQ,CAAC;IAAE3B;EAAO,CAAC,CAAC;EACrEA,OAAO,CAACY,6BAA6B,CAACH,MAAM,CAAC;EAE7C,OAAOoC,cAAc;AACvB;AAEA,SAASD,gBAAgBA,CACrB9C,MAAoB,EAAEC,IAAY,EAAEC,OAAyB;EAC/D;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM2B,QAAQ,GAAGxC,YAAY,CAACyC,eAAe,CAAC9B,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACe,KAAK,CAAC,EAAEpB,IAAI,CAAC;EAC7E,MAAMiB,SAAS,GAAGlB,MAAM,CAACK,GAAG,CACxBkB,CAAC,IAAIzB,OAAO,CAAC;IACXE,MAAM,EAAE;MAACuB;IAAC,CAAC;IACXC,KAAK,EAAE;MAACH,KAAK,EAAE,CAAC,CAAC,CAAC,EAAE9B,IAAI,CAAC6B,aAAa,CAACG,CAAC,CAACF,KAAK,CAACC,KAAK,CAACrB,IAAI,CAAC,CAAC;IAAC,CAAC;IAC7DC;GACD,CAAC,CAAC;EAEP,OAAO;IAACgB,SAAS;IAAEW;EAAQ,CAAC;AAC9B"},"metadata":{},"sourceType":"module","externalDependencies":[]}